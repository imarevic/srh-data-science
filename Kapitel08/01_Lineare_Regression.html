
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Lineare Regression &#8212; Modul Statistik und Machine Learning Modelle</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Polynomiale Regression" href="02_Polynomiale_Regression.html" />
    <link rel="prev" title="Varianzanalyse - ANOVA" href="../Kapitel07/01_Analyse_der_Varianz_ANOVA.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/srh_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Modul Statistik und Machine Learning Modelle</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Modul Statistik und Machine Learning Modelle
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Einführung in die Statistik
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Lernziele/Kapitel1_Lernziele.html">
   Lernziele
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel01/01_Deskriptive_Statistik.html">
   Deskriptive Statistik
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel01/02_Ma%C3%9Fe_der_zentralen_Tendenz.html">
   Maße der zentralen Tendenz
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel01/03_Streuungsma%C3%9Fe.html">
   Streuungsmaße
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel01/04_Ma%C3%9Fe_der_Position.html">
   Das Positionsmaß
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel01/05_Ma%C3%9Fe_der_Relation_zwischen_Variablen.html">
   Maße für die Relation zwischen Variablen
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Diskrete Zufallsvariablen
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Lernziele/Kapitel2_Lernziele.html">
   Lernziele
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel02/01_Diskrete_Zufallsvariablen.html">
   Diskrete Zufallsvariablen und ihre Wahrscheinlichkeitsverteilungen
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel02/02_Die_Binomialverteilung.html">
   Die Binomialverteilung
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel02/03_Die_Poisson_Verteilung.html">
   Die Poisson-Verteilung
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Stetige Zufallsvariablen
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Lernziele/Kapitel3_Lernziele.html">
   Lernziele
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel03/01_stetige_Zufallsvariablen.html">
   Stetige Zufallsvariablen und ihre Wahrscheinlichkeitsverteilungen
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel03/02_Die%20Normalverteilung.html">
   Die Normalverteilung
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel03/03_Die_kontinuierliche_gleichm%C3%A4%C3%9Fige_Verteilung.html">
   Die kontinuierliche gleichmäßige Verteilung
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel03/04_Die_Student_t_Verteilung.html">
   Die Student t-Verteilung
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel03/05_Die_Chi_Quadrat_Verteilung.html">
   Die Chi-Quadrat-Verteilung
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel03/06_Die_F_Verteilung.html">
   Die F-Verteilung
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Der Zentrale Grenzwertsatz
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Lernziele/Kapitel4_Lernziele.html">
   Lernziele
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel04/01_Zentraler_Grenzwertsatz.html">
   Der zentrale Grenzwertsatz
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Inferenzstatistik und Konfidenzintervalle
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Lernziele/Kapitel5_Lernziele.html">
   Lernziele
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel05/01_Inferenzstatistik_und_Konfidenzintervalle.html">
   Inferenzstatistik und Konfidenzintervalle
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Hypothesentests
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Lernziele/Kapitel6_Lernziele.html">
   Lernziele
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel06/01_Hypothesentests.html">
   Hypothesentests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel06/02_Hypothesentests_Mittelwert_einer_Grundgesamtheit.html">
   Hypothesentests für den Mittelwert einer Grundgesamtheit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel06/03_Hypothesentests_zwei_Grundgesamtheitsmittelwerte.html">
   Hypothesentests für zwei Grundgesamtheitsmittelwerte
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel06/04_Standardabweichung_der_Grundgesamtheit.html">
   Inferenz für die Standardabweichung der Grundgesamtheit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel06/05_Chi_Quadrat_Tests.html">
   Chi-Quadrat-Tests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel06/06_Inferenz_Regression_und_Korrelation.html">
   Inferenzmethoden in Regression und Korrelation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel06/07_Wahrscheinlichkeitstabellen.html">
   Wahrscheinlichkeits-Tabellen
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Varianzanalyse - ANOVA
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Lernziele/Kapitel7_Lernziele.html">
   Lernziele
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel07/01_Analyse_der_Varianz_ANOVA.html">
   Varianzanalyse - ANOVA
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lineare Regression
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Lineare Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_Polynomiale_Regression.html">
   Polynomiale Regression
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Logistische Regression
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Lernziele/Kapitel9_Lernziele.html">
   Lernziele
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Kapitel09/01_Logistische_Regression.html">
   Logistische Regression
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Literaturverzeichnis
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Literaturverzeichnis.html">
   Literaturverzeichnis
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Kapitel08/01_Lineare_Regression.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ixianslab/srh-data-science"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/ixianslab/srh-data-science/issues/new?title=Issue%20on%20page%20%2FKapitel08/01_Lineare_Regression.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/ixianslab/srh-data-science/main?urlpath=tree/notebooks/Kapitel08/01_Lineare_Regression.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#einfache-lineare-regression">
   Einfache lineare Regression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameterschatzung-methode-der-gewohnlichen-kleinsten-quadrate-ols">
   Parameterschätzung - Methode der gewöhnlichen kleinsten Quadrate (OLS)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#einfache-lineare-regression-ein-beispiel">
   Einfache lineare Regression - Ein Beispiel
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vorbereitung-der-daten">
     Vorbereitung der Daten
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#schatzung-der-parameter">
     Schätzung der Parameter
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#losen-fur-beta-0-und-beta-1-analytisch-in-python">
       Lösen für
       <span class="math notranslate nohighlight">
        \(\beta_0\)
       </span>
       und
       <span class="math notranslate nohighlight">
        \(\beta_1\)
       </span>
       analytisch in Python
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#verwenden-sie-die-funktion-linregress-bzw-ols-in-python-um-beta-0-zu-berechnen-und-beta-1">
       Verwenden Sie die Funktion
       <code class="docutils literal notranslate">
        <span class="pre">
         linregress()
        </span>
       </code>
       bzw
       <code class="docutils literal notranslate">
        <span class="pre">
         OLS()
        </span>
       </code>
       in Python, um
       <span class="math notranslate nohighlight">
        \(\beta_0\)
       </span>
       zu berechnen und
       <span class="math notranslate nohighlight">
        \(\beta_1\)
       </span>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#modelldiagnose">
   Modelldiagnose
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bestimmheitsmasz">
     Bestimmheitsmaß
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#die-methode-summary">
     Die Methode
     <code class="docutils literal notranslate">
      <span class="pre">
       summary()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#diagnostische-plots">
     Diagnostische Plots
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analyse-der-residuen">
     Analyse der Residuen
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ausreiszer-und-einfluszreiche-beobachtungen">
     Ausreißer und einflußreiche Beobachtungen
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#leverage">
       Leverage
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cook-abstand">
       Cook-Abstand
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#andere-nutzliche-regressionsdiagnosen">
       Andere nützliche Regressionsdiagnosen
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Lineare Regression</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#einfache-lineare-regression">
   Einfache lineare Regression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameterschatzung-methode-der-gewohnlichen-kleinsten-quadrate-ols">
   Parameterschätzung - Methode der gewöhnlichen kleinsten Quadrate (OLS)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#einfache-lineare-regression-ein-beispiel">
   Einfache lineare Regression - Ein Beispiel
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vorbereitung-der-daten">
     Vorbereitung der Daten
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#schatzung-der-parameter">
     Schätzung der Parameter
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#losen-fur-beta-0-und-beta-1-analytisch-in-python">
       Lösen für
       <span class="math notranslate nohighlight">
        \(\beta_0\)
       </span>
       und
       <span class="math notranslate nohighlight">
        \(\beta_1\)
       </span>
       analytisch in Python
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#verwenden-sie-die-funktion-linregress-bzw-ols-in-python-um-beta-0-zu-berechnen-und-beta-1">
       Verwenden Sie die Funktion
       <code class="docutils literal notranslate">
        <span class="pre">
         linregress()
        </span>
       </code>
       bzw
       <code class="docutils literal notranslate">
        <span class="pre">
         OLS()
        </span>
       </code>
       in Python, um
       <span class="math notranslate nohighlight">
        \(\beta_0\)
       </span>
       zu berechnen und
       <span class="math notranslate nohighlight">
        \(\beta_1\)
       </span>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#modelldiagnose">
   Modelldiagnose
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bestimmheitsmasz">
     Bestimmheitsmaß
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#die-methode-summary">
     Die Methode
     <code class="docutils literal notranslate">
      <span class="pre">
       summary()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#diagnostische-plots">
     Diagnostische Plots
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analyse-der-residuen">
     Analyse der Residuen
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ausreiszer-und-einfluszreiche-beobachtungen">
     Ausreißer und einflußreiche Beobachtungen
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#leverage">
       Leverage
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cook-abstand">
       Cook-Abstand
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#andere-nutzliche-regressionsdiagnosen">
       Andere nützliche Regressionsdiagnosen
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="lineare-regression">
<h1>Lineare Regression<a class="headerlink" href="#lineare-regression" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">t</span><span class="p">,</span> <span class="n">chi2</span><span class="p">,</span> <span class="n">linregress</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
</pre></div>
</div>
</div>
</div>
<p>Die <a href="https://de.wikipedia.org/wiki/Regressionsanalyse">Regressionsanalyse</a> ist ein statistisches Verfahren zur Schätzung der Beziehungen zwischen zwei oder mehr Variablen. Die Beziehung wird als <span class="math notranslate nohighlight">\(y \sim x\)</span> oder <span class="math notranslate nohighlight">\(y=f(x)\)</span> modelliert. Beide Modellbeschreibungen besagen, dass die Variable <span class="math notranslate nohighlight">\(y\)</span> eine Funktion von <span class="math notranslate nohighlight">\(x\)</span> ist. Daher wird die Variable <span class="math notranslate nohighlight">\(y\)</span> als <strong>Antwortvariable</strong> oder <strong>abhängige Variable</strong> bezeichnet, während die Variable <span class="math notranslate nohighlight">\(x\)</span> als <strong>Prädikatorvariable</strong> oder <strong>unabhängige Variable</strong> bezeichnet wird.</p>
<div class="section" id="einfache-lineare-regression">
<h2>Einfache lineare Regression<a class="headerlink" href="#einfache-lineare-regression" title="Permalink to this headline">¶</a></h2>
<p>In diesem Abschnitt wird eine spezielle Art der Regression behandelt, die als <a href="https://de.wikipedia.org/wiki/Lineare_Einfachregression">einfache lineare Regression</a> bezeichnet wird. In diesem speziellen Fall der Regressionsanalyse wird die Beziehung zwischen der Antwortvariablen <span class="math notranslate nohighlight">\(y\)</span> und der Prädikatorvariablen <span class="math notranslate nohighlight">\(x\)</span> in Form einer <strong>linearen</strong> Gleichung dargestellt</p>
<div class="math notranslate nohighlight">
\[y= a + bx\text{,}\]</div>
<p>wobei <span class="math notranslate nohighlight">\(a\)</span> und <span class="math notranslate nohighlight">\(b\)</span> Konstanten sind. Die Zahl <span class="math notranslate nohighlight">\(a\)</span> wird als <strong>Achsenabschnitt</strong> bezeichnet und definiert den Schnittpunkt der Regressionslinie mit der <span class="math notranslate nohighlight">\(y\)</span>-Achse (<span class="math notranslate nohighlight">\(x=0\)</span>). Die Zahl <span class="math notranslate nohighlight">\(b\)</span> wird als <strong>Regressionskoeffizient</strong> bezeichnet. Er ist ein Maß für die Steigung der <strong>Regressionsgeraden</strong>. So gibt <span class="math notranslate nohighlight">\(b\)</span> an, um wie viel sich der <span class="math notranslate nohighlight">\(y\)</span>-Wert ändert, wenn sich der <span class="math notranslate nohighlight">\(x\)</span>-Wert um <span class="math notranslate nohighlight">\(1\)</span> Einheit erhöht. Das Adjektiv <strong>einfach</strong> bezieht sich auf die Tatsache, dass die Ergebnisvariable mit einem einzigen Vorhersagewert verknüpft ist. Das Modell wird als <strong>deterministisches Modell</strong> betrachtet, da es eine genaue Beziehung zwischen <span class="math notranslate nohighlight">\(x\)</span> und <span class="math notranslate nohighlight">\(y\)</span> herstellt.</p>
<p>Lassen Sie uns ein einfaches Beispiel betrachten. Gegeben ist eine Grundgesamtheit von <span class="math notranslate nohighlight">\(n=3\)</span> Punkten mit kartesischen Koordinaten (<span class="math notranslate nohighlight">\(x_i,y_i\)</span>) von (<span class="math notranslate nohighlight">\(1,6\)</span>), (<span class="math notranslate nohighlight">\(2,8\)</span>) und (<span class="math notranslate nohighlight">\(3,10\)</span>). Diese Punkte liegen auf einer Geraden und können daher durch ein lineares Gleichungsmodell in der Form <span class="math notranslate nohighlight">\(y=a+bx\)</span> beschrieben werden, wobei der Schnittpunkt <span class="math notranslate nohighlight">\(a=4\)</span> und <span class="math notranslate nohighlight">\(b=2\)</span> ist.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">points</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">xy</span> <span class="ow">in</span> <span class="n">points</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xy</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">)</span>
<span class="n">xaxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">xaxis</span> <span class="o">+</span> <span class="mi">4</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">xaxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">)</span>

<span class="n">yaxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">yaxis</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
    <span class="sa">r</span><span class="s2">&quot;$y = a + bx = 4 + 2x$&quot;</span><span class="p">,</span>
    <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">),</span>
    <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">6.3</span><span class="p">),</span>
    <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">headwidth</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">headlength</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">),</span>
    <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span>
    <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">dx</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">head_width</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">head_length</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="mf">3.2</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">dx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">head_width</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">head_length</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.0125</span>
<span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">dx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">dy</span><span class="o">=-</span><span class="mf">2.3</span><span class="p">,</span>
    <span class="n">head_width</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
    <span class="n">head_length</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mf">0.0125</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">dx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">dy</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span>
    <span class="n">head_width</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
    <span class="n">head_length</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mf">0.0125</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="s2">&quot;$a=4$&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="s2">&quot;Zuhnahme um</span><span class="se">\n</span><span class="s2">1 Einheit&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">5.2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="s2">&quot;Zuhnahme um</span><span class="se">\n</span><span class="s2">2 Einheiten (b=2)&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="mf">3.35</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">8.2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">5.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">2.5</span><span class="p">,</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Unabhängige Variable&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Abhängige Variable&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Abhängige Variable&#39;)
</pre></div>
</div>
<img alt="../_images/01_Lineare_Regression_8_1.png" src="../_images/01_Lineare_Regression_8_1.png" />
</div>
</div>
<p>In vielen Fällen ist die Beziehung zwischen zwei Variablen <span class="math notranslate nohighlight">\(x\)</span> und <span class="math notranslate nohighlight">\(y\)</span> jedoch nicht exakt. Das liegt daran, dass die Antwortvariable <span class="math notranslate nohighlight">\(y\)</span> von anderen unbekannten und/oder zufälligen Prozessen beeinflusst wird, die von der Prädikatorvariable <span class="math notranslate nohighlight">\(x\)</span> nicht vollständig erfasst werden. In einem solchen Fall liegen die Datenpunkte nicht auf einer Geraden. Die Daten können jedoch immer noch einer zugrunde liegenden linearen Beziehung folgen. Um diese Unbekannten zu berücksichtigen, wird der linearen Modellgleichung ein <strong>Zufallsfehlerterm</strong>, bezeichnet mit <span class="math notranslate nohighlight">\(\epsilon\)</span>, hinzugefügt, was im Gegensatz zum oben beschriebenen deterministischen Modell zu einem <strong>probabilistischen Modell</strong> führt.</p>
<div class="math notranslate nohighlight">
\[y = a + b x + \epsilon\]</div>
<p>wobei angenommen wird, dass der Fehlerterm <span class="math notranslate nohighlight">\(\epsilon_i\)</span> aus unabhängigen normalverteilten Werten besteht, <span class="math notranslate nohighlight">\(\epsilon_i \sim N(0,\sigma^2)\)</span>.</p>
<p>Bei der linearen Regressionsmodellierung werden folgende Annahmen über das Modell getroffen (<span id="id1">Fahrmeir <em>et al.</em> [<a class="reference internal" href="../Literaturverzeichnis.html#id3" title="Ludwig Fahrmeir, Christian Heumann, Rita Künstler, Iris Pigeot, and Gerhard Tutz. Statistik: Der weg zur Datenanalyse. Springer-Verlag, 2016.">2016</a>]</span> s.439, <span id="id2">Frost [<a class="reference internal" href="../Literaturverzeichnis.html#id12" title="Frost. Einfache lineare Regression - Die Grundlage für komplexe Regressionsmodelle verstehen. Springer Fachmedien Wiesbaden, 2018.">2018</a>]</span>).</p>
<ul class="simple">
<li><p>Der zufällige Fehlerterm <span class="math notranslate nohighlight">\(\epsilon\)</span> hat für jedes <span class="math notranslate nohighlight">\(x\)</span> einen Mittelwert gleich Null.</p></li>
<li><p>Die mit verschiedenen Beobachtungen verbundenen Fehler sind unabhängig.</p></li>
<li><p>Für jedes gegebene <span class="math notranslate nohighlight">\(x\)</span> ist die Verteilung der Fehler normal.</p></li>
<li><p>Die Verteilung der Fehler für jedes <span class="math notranslate nohighlight">\(x\)</span> hat die gleiche (konstante) Standardabweichung, die mit <span class="math notranslate nohighlight">\(\sigma_\epsilon\)</span> bezeichnet wird.</p></li>
</ul>
<p>Betrachten wir ein weiteres Beispiel. Diesmal nehmen wir eine Zufallsstichprobe mit dem Stichprobenumfang <span class="math notranslate nohighlight">\(n=8\)</span> aus einer Grundgesamtheit. Um zu betonen, dass die Werte des Abschnitts und der Steigung aus Stichprobendaten berechnet werden, werden <span class="math notranslate nohighlight">\(a\)</span> und <span class="math notranslate nohighlight">\(b\)</span> mit <span class="math notranslate nohighlight">\(\beta_0\)</span> bzw. <span class="math notranslate nohighlight">\(\beta_1\)</span> bezeichnet. Außerdem wird der Fehlerterm <span class="math notranslate nohighlight">\(\epsilon\)</span> als <span class="math notranslate nohighlight">\(e\)</span> bezeichnet. <span class="math notranslate nohighlight">\(\beta_0\)</span>, <span class="math notranslate nohighlight">\(\beta_1\)</span> und <span class="math notranslate nohighlight">\(e\)</span> sind also Schätzungen auf der Grundlage von Stichprobendaten für die Grundgesamtheitsparameter <span class="math notranslate nohighlight">\(a\)</span>, <span class="math notranslate nohighlight">\(b\)</span> und <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p>
<div class="math notranslate nohighlight">
\[\hat y = \beta_0 + \beta_1 x + e \text{,}\]</div>
<p>wobei <span class="math notranslate nohighlight">\(\hat y\)</span> der <strong>geschätzte oder vorhergesagte Wert</strong> von <span class="math notranslate nohighlight">\(y\)</span> für einen bestimmten Wert von <span class="math notranslate nohighlight">\(x\)</span> ist.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">a</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">b</span> <span class="o">=</span> <span class="mf">2.5</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>


<span class="k">for</span> <span class="n">xy</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># ax.plot((xy), (xy[0], yhat))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">((</span><span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="p">(</span><span class="n">xy</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">yhat</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">xaxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">regline</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">xaxis</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="n">regline</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
    <span class="sa">r</span><span class="s2">&quot;$\hat y = \beta_0 + \beta_1x$&quot;</span><span class="p">,</span>
    <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">18</span><span class="p">),</span>
    <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span>
    <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">headwidth</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">headlength</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">),</span>
    <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span>
    <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="s2">&quot;$(x_i, y_i)$&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="mf">2.9</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">17.8</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="s2">&quot;$e_i = y_i - \hat y_1$&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="mf">1.6</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">13.8</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">9.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Unabhängige Variable&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Abhängige Variable&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Abhängige Variable&#39;)
</pre></div>
</div>
<img alt="../_images/01_Lineare_Regression_15_1.png" src="../_images/01_Lineare_Regression_15_1.png" />
</div>
</div>
<p>Der Fehler <span class="math notranslate nohighlight">\(e_i\)</span> für jedes einzelne Wertepaar (<span class="math notranslate nohighlight">\(x_i,y_i\)</span>), auch <strong>Residuum</strong> genannt, wird aus der Differenz zwischen dem beobachteten Wert <span class="math notranslate nohighlight">\(y_i\)</span> und dem durch <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> gegebenen vorhergesagten Wert errechnet.</p>
<div class="math notranslate nohighlight">
\[e_i = y_i - \hat y_i\]</div>
<p>Je nach Datenlage ist <span class="math notranslate nohighlight">\(e_i\)</span> eine negative Zahl, wenn <span class="math notranslate nohighlight">\(y_i\)</span> unterhalb der Regressionslinie liegt, oder eine positive Zahl, wenn <span class="math notranslate nohighlight">\(y_i\)</span> oberhalb der Regressionslinie liegt.</p>
</div>
<div class="section" id="parameterschatzung-methode-der-gewohnlichen-kleinsten-quadrate-ols">
<h2>Parameterschätzung - Methode der gewöhnlichen kleinsten Quadrate (OLS)<a class="headerlink" href="#parameterschatzung-methode-der-gewohnlichen-kleinsten-quadrate-ols" title="Permalink to this headline">¶</a></h2>
<p>Da wir nun die Beschränkungen des deterministischen Modells gelockert und einen Fehlerterm <span class="math notranslate nohighlight">\(\epsilon\)</span> eingeführt haben, stoßen wir auf ein weiteres Problem. Es gibt unendlich viele Regressionsgeraden, die die Spezifikationen des probabilistischen Modells erfüllen.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">a</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">b</span> <span class="o">=</span> <span class="mf">2.5</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">xaxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="mi">3</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="mi">3</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="mi">5</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="k">for</span> <span class="n">e</span><span class="p">,</span> <span class="p">(</span><span class="n">__a</span><span class="p">,</span> <span class="n">__b</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">_a</span><span class="p">,</span> <span class="n">_b</span><span class="p">)):</span>
    <span class="n">regline</span> <span class="o">=</span> <span class="n">__a</span> <span class="o">+</span> <span class="n">__b</span> <span class="o">*</span> <span class="n">xaxis</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="n">regline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># [(6.161682980460268, 1.3593855069401755),</span>
<span class="c1">#  (0.8958678353055358, 3.5287158712720164),</span>
<span class="c1">#  (5.331259776126706, 2.3273786695000847)]</span>

<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$\hat y = 0.90 + 3.53x+e$&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">22</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$\hat y = 5.336 + 2.33x+e$&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="mf">6.5</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$\hat y = 6.16 + 1.36x+e$&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="mf">6.5</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>


<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">9.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Unabhängige Variable&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Abhängige Variable&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Abhängige Variable&#39;)
</pre></div>
</div>
<img alt="../_images/01_Lineare_Regression_21_1.png" src="../_images/01_Lineare_Regression_21_1.png" />
</div>
</div>
<p>Offensichtlich brauchen wir eine Strategie, um diejenige Regressionsgerade auszuwählen, die das beste Modell zur Beschreibung der Daten darstellt. In diesem Abschnitt befassen wir uns mit einer der gängigsten Methoden zur Erfüllung dieser Aufgabe, der so genannten Methode der <a href="https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate">gewöhnlichen kleinsten Quadrate</a> (englisch ordinary least squares, kurz: <span class="math notranslate nohighlight">\(OLS\)</span>).</p>
<p>Wie im vorigen Abschnitt erwähnt, wird für jedes bestimmte Wertepaar (<span class="math notranslate nohighlight">\(x_1,y_1\)</span>)
wird der Fehler <span class="math notranslate nohighlight">\(e_i\)</span> durch <span class="math notranslate nohighlight">\(y_1-\hat y\)</span> berechnet. Um die beste Anpassungsgerade für die gegebenen Daten zu erhalten, wird die <strong>Summe der Fehlerquadrate</strong>, bezeichnet als <span class="math notranslate nohighlight">\(SSE\)</span>, minimiert.</p>
<div class="math notranslate nohighlight">
\[min\; SSE = \sum_{i=1}^n e_i^2=\sum_{i=1}^n (y - \hat y)^2\]</div>
<p>Für das einfache lineare Modell gibt es eine analytische Lösung für <span class="math notranslate nohighlight">\(\beta_1\)</span></p>
<div class="math notranslate nohighlight">
\[\hat{\beta_1} = \frac{\sum_{i=1}^n ((x_i- \bar x) (y_i-\bar y))}{\sum_{i=1}^n (x_i-\bar x)^2} = \frac{cov(x,y)}{var(x)}\text{,}\]</div>
<p>und <span class="math notranslate nohighlight">\(\beta_0\)</span>:</p>
<div class="math notranslate nohighlight">
\[\hat{\beta_0} = \bar y -\hat{\beta_1} \bar x\]</div>
<p>Die <span class="math notranslate nohighlight">\(OLS\)</span> liefert die Maximum-Likelihood-Schätzung für <span class="math notranslate nohighlight">\(\hat \beta\)</span>, wenn die Parameter die gleiche Varianz haben und unkorreliert sind und die Residuen <span class="math notranslate nohighlight">\(\epsilon\)</span> unkorreliert sind und einer Gaußschen Verteilung folgen (<a href="https://de.wikipedia.org/wiki/Homoskedastizit%C3%A4t_und_Heteroskedastizit%C3%A4t">Homoskedastizität</a>).</p>
</div>
<div class="section" id="einfache-lineare-regression-ein-beispiel">
<h2>Einfache lineare Regression - Ein Beispiel<a class="headerlink" href="#einfache-lineare-regression-ein-beispiel" title="Permalink to this headline">¶</a></h2>
<p>Um einige praktische Erfahrungen zu sammeln, wenden wir die einfache lineare Regression in einer Übung an. Dazu laden wir den <code class="docutils literal notranslate"><span class="pre">students</span></code> Datensatz. Sie können die Datei <code class="docutils literal notranslate"><span class="pre">students.csv</span></code> <a href="https://userpage.fu-berlin.de/soga/200/2010_data_sets/students.csv">hier</a> herunterladen. Importieren Sie den Datensatz und geben Sie ihm einen passenden Namen.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Lese Datei students.csv als Dataframe ein</span>
<span class="n">students</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../../data/students.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Der <code class="docutils literal notranslate"><span class="pre">students</span></code> Datensatz besteht aus 8239 Zeilen, von denen jede einen bestimmten Studenten repräsentiert, und 16 Spalten, von denen jede einer Variable/einem Merkmal entspricht, das sich auf diesen bestimmten Studenten bezieht. Diese selbsterklärenden Variablen sind: <a class="reference external" href="http://stud.id">stud.id</a>, name, gender, age, height, weight, religion, nc.score, semester, major, minor, score1, score2, online.tutorial, graduated, salary.</p>
<p>Um die <strong>einfache lineare Regression</strong> zu veranschaulichen, untersuchen wir die Beziehung zwischen zwei Variablen, <code class="docutils literal notranslate"><span class="pre">height</span></code> der Studenten als Prädiktorvariable und <code class="docutils literal notranslate"><span class="pre">weight</span></code> der Studierenden als Antwortvariable.</p>
<div class="section" id="vorbereitung-der-daten">
<h3>Vorbereitung der Daten<a class="headerlink" href="#vorbereitung-der-daten" title="Permalink to this headline">¶</a></h3>
<p>Zur Datenaufbereitung ziehen wir eine Zufallsstichprobe von <span class="math notranslate nohighlight">\(12\)</span> Studenten aus dem Datensatz und erstellen einen Datensatz mit den zwei Variablen von Interesse (<code class="docutils literal notranslate"><span class="pre">height</span></code> und <code class="docutils literal notranslate"><span class="pre">weight</span></code>). Außerdem stellen wir die Daten in Form eines Streudiagramms dar, um die zugrunde liegende lineare Beziehung zwischen den beiden Variablen zu visualisieren.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">students</span><span class="p">[[</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="s2">&quot;height&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.collections.PathCollection at 0x17218fee0&gt;
</pre></div>
</div>
<img alt="../_images/01_Lineare_Regression_36_1.png" src="../_images/01_Lineare_Regression_36_1.png" />
</div>
</div>
<p>Die visuelle Inspektion bestätigt unsere Vermutung, dass die Beziehung zwischen der Größe und der Gewichtsvariable ungefähr linear ist. Mit anderen Worten: Mit zunehmender Größe neigt der einzelne Studierende dazu, ein höheres Gewicht zu haben.</p>
</div>
<div class="section" id="schatzung-der-parameter">
<h3>Schätzung der Parameter<a class="headerlink" href="#schatzung-der-parameter" title="Permalink to this headline">¶</a></h3>
<div class="section" id="losen-fur-beta-0-und-beta-1-analytisch-in-python">
<h4>Lösen für <span class="math notranslate nohighlight">\(\beta_0\)</span> und <span class="math notranslate nohighlight">\(\beta_1\)</span> analytisch in Python<a class="headerlink" href="#losen-fur-beta-0-und-beta-1-analytisch-in-python" title="Permalink to this headline">¶</a></h4>
<p>Wie im vorherigen Abschnitt gezeigt, können die Parameter <span class="math notranslate nohighlight">\(\beta_0\)</span> und <span class="math notranslate nohighlight">\(\beta_1\)</span> eines einfachen linearen Modells analytisch berechnet werden. Erinnern Sie sich an die Gleichung für ein lineares Modell aus Stichprobendaten</p>
<div class="math notranslate nohighlight">
\[\hat y = \beta_0 + \beta_1 x + e \text{,}\]</div>
<p>für <span class="math notranslate nohighlight">\(\beta_1\)</span></p>
<div class="math notranslate nohighlight">
\[\hat{\beta_1} = \frac{\sum_{i=1}^n ((x_i- \bar x) (y_i-\bar y))}{\sum_{i=1}^n (x_i-\bar x)^2} = \frac{cov(x,y)}{var(x)}\text{,}\]</div>
<p>und für <span class="math notranslate nohighlight">\(\beta_0\)</span></p>
<div class="math notranslate nohighlight">
\[\hat{\beta_0} = \bar y -\hat{\beta_1} \bar x\]</div>
<p>Zum besseren Verständnis verwenden wir Python, um die einzelnen Terme zu berechnen</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Berechne b1</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span>
<span class="n">x_bar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">y_bar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_bar</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_bar</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_bar</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">b1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6507615230460924
</pre></div>
</div>
</div>
</div>
<p>Die Steigung des Regressionsmodells beträgt ungefähr <span class="math notranslate nohighlight">\(0,65\)</span>. Zur Überprüfung der Korrektheit berechnen wir das Verhältnis der Kovarianz von <span class="math notranslate nohighlight">\(x\)</span> und <span class="math notranslate nohighlight">\(y\)</span> mit der Funktion <code class="docutils literal notranslate"><span class="pre">cov()</span></code> und die Varianz von <span class="math notranslate nohighlight">\(x\)</span> mit der Funktion <code class="docutils literal notranslate"><span class="pre">var()</span></code> und vergleichen es mit dem Ergebnis von oben.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6507615230460924
</pre></div>
</div>
</div>
</div>
<p>Eine perfekte Übereinstimmung!</p>
<p>Weiter berechnen wir <span class="math notranslate nohighlight">\(\beta_0\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Berechne b0</span>
<span class="n">b0</span> <span class="o">=</span> <span class="n">y_bar</span> <span class="o">-</span> <span class="n">b1</span> <span class="o">*</span> <span class="n">x_bar</span>
<span class="n">b0</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-39.443206412825674
</pre></div>
</div>
</div>
</div>
<p>Der Achsenabschnitt <span class="math notranslate nohighlight">\(\beta_0\)</span> des Regressionsmodells beträgt ungefähr <span class="math notranslate nohighlight">\(-39,44\)</span>.</p>
<p>Wir können also das Regressionsmodell aufschreiben</p>
<div class="math notranslate nohighlight">
\[\text{Gewicht} = -39,44 + 0,65 \times \text{Höhe}\]</div>
<p>Auf der Grundlage dieser Gleichung können wir nun das Gewicht eines Studenten anhand seiner Größe bestimmen. Lassen Sie uns zum Spaß das Gewicht von Studierenden mit einer Größe von <span class="math notranslate nohighlight">\(156\)</span>, <span class="math notranslate nohighlight">\(178\)</span> und <span class="math notranslate nohighlight">\(192\)</span> cm vorhersagen.</p>
<div class="math notranslate nohighlight">
\[\text{Gewicht}_{156} = -39,44 + 0,65 \times \text{156} \approx 62 \ \text{kg}\]</div>
<div class="math notranslate nohighlight">
\[\text{Gewicht}_{178} = -39,44 + 0,65 \times \text{178} \approx 76 \ \text{kg}\]</div>
<div class="math notranslate nohighlight">
\[\text{Gewicht}_{192} = -39,44 + 0,65 \times \text{192} \approx 85 \ \text{kg}\]</div>
</div>
<div class="section" id="verwenden-sie-die-funktion-linregress-bzw-ols-in-python-um-beta-0-zu-berechnen-und-beta-1">
<h4>Verwenden Sie die Funktion <code class="docutils literal notranslate"><span class="pre">linregress()</span></code> bzw <code class="docutils literal notranslate"><span class="pre">OLS()</span></code> in Python, um <span class="math notranslate nohighlight">\(\beta_0\)</span> zu berechnen und <span class="math notranslate nohighlight">\(\beta_1\)</span><a class="headerlink" href="#verwenden-sie-die-funktion-linregress-bzw-ols-in-python-um-beta-0-zu-berechnen-und-beta-1" title="Permalink to this headline">¶</a></h4>
<p>Zum einen können wir die Funktion <code class="docutils literal notranslate"><span class="pre">linregress()</span></code> nutzen um <span class="math notranslate nohighlight">\(\beta_0\)</span> und <span class="math notranslate nohighlight">\(\beta_1\)</span> zu berechnen.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gradient</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">stderr</span> <span class="o">=</span> <span class="n">linregress</span><span class="p">(</span>
    <span class="n">data</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;beta_0 = </span><span class="si">{</span><span class="n">intercept</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;beta_1 = </span><span class="si">{</span><span class="n">gradient</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>beta_0 = -39.44320641282566
beta_1 = 0.6507615230460922
</pre></div>
</div>
</div>
</div>
<p>Eine andere Möglichkeit ist es das Paket <a class="reference external" href="https://www.statsmodels.org/stable/index.html"><code class="docutils literal notranslate"><span class="pre">statsmodels</span></code></a> und die Funktion <code class="docutils literal notranslate"><span class="pre">OLS()</span></code> zu nutzen, die zusätzlich zur Berechnung von <span class="math notranslate nohighlight">\(\beta_0 , \beta_1\)</span> viele weitere Möglichkeiten bietet</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">params</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>const    -39.443206
height     0.650762
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Die Ausgabe über die Methode <code class="docutils literal notranslate"><span class="pre">params</span></code> liefert den Achsenabschnitt und den Regressionskoeffizienten. Weiters kann die Methode <code class="docutils literal notranslate"><span class="pre">summary()</span></code> nützlich sein, wenn Sie auf andere Eigenschaft des Modellobjekts zugreifen möchten.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/miniconda3/envs/srh/lib/python3.10/site-packages/scipy/stats/_stats_py.py:1477: UserWarning: kurtosistest only valid for n&gt;=20 ... continuing anyway, n=12
  warnings.warn(&quot;kurtosistest only valid for n&gt;=20 ... continuing &quot;
</pre></div>
</div>
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>         <td>weight</td>      <th>  R-squared:         </th> <td>   0.921</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.913</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   115.9</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sun, 03 Jul 2022</td> <th>  Prob (F-statistic):</th> <td>8.05e-07</td>
</tr>
<tr>
  <th>Time:</th>                 <td>17:51:08</td>     <th>  Log-Likelihood:    </th> <td> -22.602</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    12</td>      <th>  AIC:               </th> <td>   49.20</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    10</td>      <th>  BIC:               </th> <td>   50.17</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th>  <td>  -39.4432</td> <td>   10.057</td> <td>   -3.922</td> <td> 0.003</td> <td>  -61.851</td> <td>  -17.036</td>
</tr>
<tr>
  <th>height</th> <td>    0.6508</td> <td>    0.060</td> <td>   10.766</td> <td> 0.000</td> <td>    0.516</td> <td>    0.785</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 2.161</td> <th>  Durbin-Watson:     </th> <td>   1.778</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.339</td> <th>  Jarque-Bera (JB):  </th> <td>   0.923</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.110</td> <th>  Prob(JB):          </th> <td>   0.630</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 1.659</td> <th>  Cond. No.          </th> <td>3.33e+03</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.33e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.</div></div>
</div>
<p>Die Methode <code class="docutils literal notranslate"><span class="pre">conf_int()</span></code> gibt das Konfidenzintervall für die Modellkoeffizienten für ein bestimmtes Konfidenzniveau zurück (Standardeinstellung entspricht <span class="math notranslate nohighlight">\(\alpha = 0,05\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">conf_int</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>const</th>
      <td>-61.850735</td>
      <td>-17.035678</td>
    </tr>
    <tr>
      <th>height</th>
      <td>0.516081</td>
      <td>0.785442</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Eine weitere nützliche Extraktormethode ist die Funktion <code class="docutils literal notranslate"><span class="pre">resid()</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">resid</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>339     0.815271
2124   -1.037014
2388    1.218317
2727   -1.527876
2767   -1.035491
3594    1.164509
4152    2.655371
4433    2.072124
5100   -1.038537
7099   -2.438537
7136    0.930501
8170   -1.778637
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Wir können sofort überprüfen, ob die Summe der Residuen (<span class="math notranslate nohighlight">\(\sum e\)</span>) nahe bei Null liegt.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">resid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-6.394884621840902e-14
</pre></div>
</div>
</div>
</div>
<p>Cool, nahe an Null!</p>
<p>Um die erhaltene Regressionslinie zu zeichnen, verwenden wir die Funktion <span class="math notranslate nohighlight">\(y = \beta_0 + \beta_1 x\)</span>, die Linien auf der Grundlage des Achsenabschnitts (<span class="math notranslate nohighlight">\(\beta_0\)</span>) und der Steigung (<span class="math notranslate nohighlight">\(\beta_1\)</span>) zeichnet. Wir verwenden den Syntax <code class="docutils literal notranslate"><span class="pre">plot([x_1,x_2],[y_1,y_2])</span></code> um die Regressionsgerade zu plotten.</p>
<p>Eine weitere besonders interessante Extraktormethode ist <code class="docutils literal notranslate"><span class="pre">predict()</span></code>. Wenn sie nicht spezifiziert ist, gibt die Methode <code class="docutils literal notranslate"><span class="pre">predict()</span></code> <span class="math notranslate nohighlight">\(\hat y_i\)</span> für jedes einzelne <span class="math notranslate nohighlight">\(x_i\)</span> zurück; ähnlich wie die Methode <code class="docutils literal notranslate"><span class="pre">fittedvalues</span></code>. Man kann jedoch auch neue Daten angeben und die Funktion <code class="docutils literal notranslate"><span class="pre">predict()</span></code> wird <span class="math notranslate nohighlight">\(\hat y_i\)</span> für jedes gegebene <span class="math notranslate nohighlight">\(x_i\)</span> vorhersagen. Beachten Sie, dass die neuen Daten ein Data-Frame-Objekt oder eine Liste sein müssen.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>339     69.884729
2124    71.837014
2388    67.281683
2727    64.027876
2767    70.535491
3594    70.535491
4152    78.344629
4433    64.027876
5100    73.138537
7099    73.138537
7136    56.869499
8170    64.678637
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fittedvalues</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>339     69.884729
2124    71.837014
2388    67.281683
2727    64.027876
2767    70.535491
3594    70.535491
4152    78.344629
4433    64.027876
5100    73.138537
7099    73.138537
7136    56.869499
8170    64.678637
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Datapoints&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">],</span> <span class="n">model</span><span class="o">.</span><span class="n">fittedvalues</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Fitted values&quot;</span><span class="p">)</span>
<span class="c1"># create regression line</span>
<span class="n">x_axis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">140</span><span class="p">,</span> <span class="mi">190</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">_x_axis</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x_axis</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">_x_axis</span><span class="p">))</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Gewicht&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Körpergrösse&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x1722c7250&gt;
</pre></div>
</div>
<img alt="../_images/01_Lineare_Regression_75_1.png" src="../_images/01_Lineare_Regression_75_1.png" />
</div>
</div>
<p>Darüber hinaus bietet Python einen einfachen Ansatz zur Erstellung von Fehlerbereichen um die angepasste Regressionslinie. Es gibt zwei Arten von Bändern, die als <em>schmale</em> und <em>breite</em> Bänder bezeichnet werden. Die schmalen Bänder, die so genannten <a href="https://de.wikipedia.org/wiki/Konfidenzintervall">Konfidenzbänder</a>, spiegeln die Unsicherheit über die Linie selbst wider. Die Bänder sind schmal, wenn es viele Beobachtungen gibt, und spiegeln eine gut bestimmte Linie wider. Die breiten Banden, die so genannten <a href="https://de.wikipedia.org/wiki/Konfidenzintervall">Prognosebänder</a> (<span id="id3">Frost [<a class="reference internal" href="../Literaturverzeichnis.html#id12" title="Frost. Einfache lineare Regression - Die Grundlage für komplexe Regressionsmodelle verstehen. Springer Fachmedien Wiesbaden, 2018.">2018</a>]</span> s.27), beinhalten die Unsicherheit über zukünftige Beobachtungen. Diese Bänder erfassen die Mehrheit der beobachteten Punkte und fallen nicht zu einer Linie zusammen, wenn die Anzahl der Beobachtungen zunimmt.</p>
<p>Um diese Unsicherheitsbänder zu berechnen, wenden wir die Methode <code class="docutils literal notranslate"><span class="pre">get_prediction()</span></code> an und fügen die Methode <code class="docutils literal notranslate"><span class="pre">summary_frame()</span></code> hinzu, um den Vektor der vorhergesagten Werte zu erhalten, der mit Grenzwerten ergänzt wird.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">140</span><span class="p">,</span> <span class="mi">190</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
<span class="n">model_predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_prediction</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span><span class="o">.</span><span class="n">summary_frame</span><span class="p">()</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Beobachtungen&quot;</span><span class="p">)</span>

<span class="c1"># create regression line</span>
<span class="n">x_axis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">140</span><span class="p">,</span> <span class="mi">190</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">model_predictions</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Regressionslinie&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
    <span class="n">x_axis</span><span class="p">,</span>
    <span class="n">model_predictions</span><span class="p">[</span><span class="s2">&quot;obs_ci_lower&quot;</span><span class="p">],</span>
    <span class="n">model_predictions</span><span class="p">[</span><span class="s2">&quot;obs_ci_upper&quot;</span><span class="p">],</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Prognoseinterval&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
    <span class="n">x_axis</span><span class="p">,</span>
    <span class="n">model_predictions</span><span class="p">[</span><span class="s2">&quot;mean_ci_lower&quot;</span><span class="p">],</span>
    <span class="n">model_predictions</span><span class="p">[</span><span class="s2">&quot;mean_ci_upper&quot;</span><span class="p">],</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Konvidenzinterval&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Gewicht&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Körpergrösse&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x172361000&gt;
</pre></div>
</div>
<img alt="../_images/01_Lineare_Regression_77_1.png" src="../_images/01_Lineare_Regression_77_1.png" />
</div>
</div>
<p>Es gibt viele weitere Attribute und Methoden eines <code class="docutils literal notranslate"><span class="pre">OLS</span></code>-Objekts auf die zugegriffen werden kann. Die Funktion <code class="docutils literal notranslate"><span class="pre">dir()</span></code> gibt einen Überblick über die Struktur des Modellobjekts.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">dir</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;HC0_se&#39;,
 &#39;HC1_se&#39;,
 &#39;HC2_se&#39;,
 &#39;HC3_se&#39;,
 &#39;_HCCM&#39;,
 &#39;__class__&#39;,
 &#39;__delattr__&#39;,
 &#39;__dict__&#39;,
 &#39;__dir__&#39;,
 &#39;__doc__&#39;,
 &#39;__eq__&#39;,
 &#39;__format__&#39;,
 &#39;__ge__&#39;,
 &#39;__getattribute__&#39;,
 &#39;__gt__&#39;,
 &#39;__hash__&#39;,
 &#39;__init__&#39;,
 &#39;__init_subclass__&#39;,
 &#39;__le__&#39;,
 &#39;__lt__&#39;,
 &#39;__module__&#39;,
 &#39;__ne__&#39;,
 &#39;__new__&#39;,
 &#39;__reduce__&#39;,
 &#39;__reduce_ex__&#39;,
 &#39;__repr__&#39;,
 &#39;__setattr__&#39;,
 &#39;__sizeof__&#39;,
 &#39;__str__&#39;,
 &#39;__subclasshook__&#39;,
 &#39;__weakref__&#39;,
 &#39;_abat_diagonal&#39;,
 &#39;_cache&#39;,
 &#39;_data_attr&#39;,
 &#39;_data_in_cache&#39;,
 &#39;_get_robustcov_results&#39;,
 &#39;_is_nested&#39;,
 &#39;_use_t&#39;,
 &#39;_wexog_singular_values&#39;,
 &#39;aic&#39;,
 &#39;bic&#39;,
 &#39;bse&#39;,
 &#39;centered_tss&#39;,
 &#39;compare_f_test&#39;,
 &#39;compare_lm_test&#39;,
 &#39;compare_lr_test&#39;,
 &#39;condition_number&#39;,
 &#39;conf_int&#39;,
 &#39;conf_int_el&#39;,
 &#39;cov_HC0&#39;,
 &#39;cov_HC1&#39;,
 &#39;cov_HC2&#39;,
 &#39;cov_HC3&#39;,
 &#39;cov_kwds&#39;,
 &#39;cov_params&#39;,
 &#39;cov_type&#39;,
 &#39;df_model&#39;,
 &#39;df_resid&#39;,
 &#39;diagn&#39;,
 &#39;eigenvals&#39;,
 &#39;el_test&#39;,
 &#39;ess&#39;,
 &#39;f_pvalue&#39;,
 &#39;f_test&#39;,
 &#39;fittedvalues&#39;,
 &#39;fvalue&#39;,
 &#39;get_influence&#39;,
 &#39;get_prediction&#39;,
 &#39;get_robustcov_results&#39;,
 &#39;info_criteria&#39;,
 &#39;initialize&#39;,
 &#39;k_constant&#39;,
 &#39;llf&#39;,
 &#39;load&#39;,
 &#39;model&#39;,
 &#39;mse_model&#39;,
 &#39;mse_resid&#39;,
 &#39;mse_total&#39;,
 &#39;nobs&#39;,
 &#39;normalized_cov_params&#39;,
 &#39;outlier_test&#39;,
 &#39;params&#39;,
 &#39;predict&#39;,
 &#39;pvalues&#39;,
 &#39;remove_data&#39;,
 &#39;resid&#39;,
 &#39;resid_pearson&#39;,
 &#39;rsquared&#39;,
 &#39;rsquared_adj&#39;,
 &#39;save&#39;,
 &#39;scale&#39;,
 &#39;ssr&#39;,
 &#39;summary&#39;,
 &#39;summary2&#39;,
 &#39;t_test&#39;,
 &#39;t_test_pairwise&#39;,
 &#39;tvalues&#39;,
 &#39;uncentered_tss&#39;,
 &#39;use_t&#39;,
 &#39;wald_test&#39;,
 &#39;wald_test_terms&#39;,
 &#39;wresid&#39;]
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="modelldiagnose">
<h2>Modelldiagnose<a class="headerlink" href="#modelldiagnose" title="Permalink to this headline">¶</a></h2>
<p><a href="https://de.wikipedia.org/wiki/Regressionsdiagnostik">Regressionsdiagnostik</a> beinhaltet eine Reihe von Verfahren, die zur Bewertung der numerischen Ergebnisse einer Regressionsanalyse angewandt werden. Die Verfahren umfassen Methoden der grafischen und quantitativen Analyse oder formale statistische Hypothesentests. In diesem Abschnitt konzentrieren wir uns auf die beiden wichtigsten Methoden, die grafische und die quantitative Analyse. Statistische Hypothesentests für Regressionsprobleme finden Sie im Abschnitt über <em>Hypothesentests</em>.</p>
<div class="section" id="bestimmheitsmasz">
<h3>Bestimmheitsmaß<a class="headerlink" href="#bestimmheitsmasz" title="Permalink to this headline">¶</a></h3>
<p>Der <a href="https://de.wikipedia.org/wiki/Bestimmtheitsma%C3%9F">Bestimmtheitsmaß</a>, auch als <span class="math notranslate nohighlight">\(R^2\)</span> bezeichnet, ist der Anteil der Variation der beobachteten Werte, der durch die Regressionsgleichung erklärt wird. Mit anderen Worten: <span class="math notranslate nohighlight">\(R^2\)</span> ist ein statistisches Maß dafür, wie gut die Regressionsgerade die realen Datenpunkte annähert; es ist also ein Maß für die Anpassungsfähigkeit des Modells.</p>
<p>Die Gesamtvariation der Antwortvariablen <span class="math notranslate nohighlight">\(y\)</span>
basiert auf der Abweichung jedes beobachteten Wertes <span class="math notranslate nohighlight">\(y_i\)</span> vom Mittelwert <span class="math notranslate nohighlight">\(\bar y\)</span>. Diese Größe wird als <strong>Gesamtsumme der Quadrate, <span class="math notranslate nohighlight">\(SST\)</span></strong>, bezeichnet und ist gegeben durch</p>
<div class="math notranslate nohighlight">
\[SST = \sum (y_i - \bar y)^2\text{.}\]</div>
<p>Diese Gesamtsumme der Quadrate (<span class="math notranslate nohighlight">\(SST\)</span>) kann in zwei Teile zerlegt werden: die durch die Regressionslinie erklärte Abweichung <span class="math notranslate nohighlight">\(\hat y_i- \bar y\)</span> und die verbleibende unerklärte Abweichung <span class="math notranslate nohighlight">\(y_i-\hat y_i\)</span>. Folglich wird der Anteil der Variation, der durch die Regression erklärt wird, als <strong>Summe der Quadrate aufgrund der Regression</strong>, <span class="math notranslate nohighlight">\(SSR\)</span>, bezeichnet und ist gegeben durch</p>
<div class="math notranslate nohighlight">
\[SSR = \sum (\hat y_i- \bar y)^2\text{.}\]</div>
<p>Das Verhältnis zwischen der Summe der Quadrate aufgrund der Regression (<span class="math notranslate nohighlight">\(SSR\)</span>) und der Gesamtsumme der Quadrate (<span class="math notranslate nohighlight">\(SST\)</span>) wird als Bestimmtheitsmaß bezeichnet und mit <span class="math notranslate nohighlight">\(R^2\)</span> angegeben.</p>
<div class="math notranslate nohighlight">
\[R^2 = \frac{SSR}{SST}\]</div>
<p><span class="math notranslate nohighlight">\(R^2\)</span> liegt zwischen <span class="math notranslate nohighlight">\(0\)</span> und <span class="math notranslate nohighlight">\(1\)</span>. Ein Wert nahe <span class="math notranslate nohighlight">\(0\)</span> deutet darauf hin, dass die Regressionsgleichung nicht in der Lage ist, die Daten zu erklären. Ein <span class="math notranslate nohighlight">\(R^2\)</span> von <span class="math notranslate nohighlight">\(1\)</span> zeigt an, dass die Regressionsgerade perfekt zu den Daten passt.</p>
<p>Der Vollständigkeit halber wird die Variation in den beobachteten Werten der Reaktionsvariablen, die nicht durch die Regression erklärt wird, als <strong>Summe der quadrierten Fehler der Vorhersage</strong> (<span class="math notranslate nohighlight">\(SSE\)</span>) bezeichnet und ist gegeben durch</p>
<div class="math notranslate nohighlight">
\[SSE = \sum (y_i-\hat y_i)^2\text{.}\]</div>
<p>Erinnern Sie sich, dass die <span class="math notranslate nohighlight">\(SSE\)</span>-Größe minimiert wird, um die beste Regressionslinie zur Beschreibung der Daten zu erhalten, auch bekannt als die <a href="https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate">Methode der gewöhnlichen kleinsten Quadrate</a> (<span class="math notranslate nohighlight">\(OLS\)</span>).</p>
</div>
<div class="section" id="die-methode-summary">
<h3>Die Methode <code class="docutils literal notranslate"><span class="pre">summary()</span></code><a class="headerlink" href="#die-methode-summary" title="Permalink to this headline">¶</a></h3>
<p>Eine grundlegendes Mittel für die Regressionsdiagnose in Python ist die Methode <code class="docutils literal notranslate"><span class="pre">summary()</span></code>. Die Funktion <code class="docutils literal notranslate"><span class="pre">OLS()</span></code> gibt ein Modellobjekt zurück. Dieses <code class="docutils literal notranslate"><span class="pre">OLS()</span></code>-Objekt enthält die Modelleigenschaften, die durch Anwendung der Methode <code class="docutils literal notranslate"><span class="pre">summary()</span></code> untersucht werden können.</p>
<p>Zu Demonstrationszwecken wird dasselbe Modell wie im vorherigen Abschnitt verwendet.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Lese Datei students.csv als Dataframe ein; Indexspalte wird übersprungen</span>
<span class="n">students</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../../data/students.csv&quot;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">12</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">students</span><span class="p">[[</span><span class="s2">&quot;height&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># make the predictions by the model</span>

<span class="c1"># Lese Modellwerte aus</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/miniconda3/envs/srh/lib/python3.10/site-packages/scipy/stats/_stats_py.py:1477: UserWarning: kurtosistest only valid for n&gt;=20 ... continuing anyway, n=12
  warnings.warn(&quot;kurtosistest only valid for n&gt;=20 ... continuing &quot;
</pre></div>
</div>
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>         <td>weight</td>      <th>  R-squared:         </th> <td>   0.921</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.913</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   115.9</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sun, 03 Jul 2022</td> <th>  Prob (F-statistic):</th> <td>8.05e-07</td>
</tr>
<tr>
  <th>Time:</th>                 <td>17:51:09</td>     <th>  Log-Likelihood:    </th> <td> -22.602</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    12</td>      <th>  AIC:               </th> <td>   49.20</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    10</td>      <th>  BIC:               </th> <td>   50.17</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th>  <td>  -39.4432</td> <td>   10.057</td> <td>   -3.922</td> <td> 0.003</td> <td>  -61.851</td> <td>  -17.036</td>
</tr>
<tr>
  <th>height</th> <td>    0.6508</td> <td>    0.060</td> <td>   10.766</td> <td> 0.000</td> <td>    0.516</td> <td>    0.785</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 2.161</td> <th>  Durbin-Watson:     </th> <td>   1.442</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.339</td> <th>  Jarque-Bera (JB):  </th> <td>   0.923</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.110</td> <th>  Prob(JB):          </th> <td>   0.630</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 1.659</td> <th>  Cond. No.          </th> <td>3.33e+03</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.33e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.</div></div>
</div>
<ul class="simple">
<li><p>Die Ausgabe der Methode <code class="docutils literal notranslate"><span class="pre">summary()</span></code> beginnt mit einer Wiederholung der abhängigen Variable und der angewandten Methode (in diesem Fall <span class="math notranslate nohighlight">\(OLS\)</span>).</p></li>
<li><p>Die nächste Zeile zeigt <span class="math notranslate nohighlight">\(R^2\)</span>, den quadrierten <a href="https://de.wikipedia.org/wiki/Korrelationskoeffizient">Pearson Korrelationskoeffizienten</a>, auch bekannt als <a href="https://de.wikipedia.org/wiki/Bestimmtheitsma%C3%9F">Bestimmtheitsmaß</a> und das angepasste <span class="math notranslate nohighlight">\(R^2\)</span>, ein statistisches Maß, das für die Merkmalsauswahl bei der Regressionsanalyse mit mehreren Prädiktoren (multiple Regression) verwendet werden kann.</p></li>
<li><p>Die darauf folgenden Zeilen zeigen die <span class="math notranslate nohighlight">\(F\)</span>-Statistik, die Anzahl der Beobachtungen (Datenpunkte) und Freiheitsgrade.</p></li>
<li><p>In den nächsten Zeilen werden der Regressionskoeffizient (unter <code class="docutils literal notranslate"><span class="pre">height</span></code>) und der Achsenabschnitt (unter <code class="docutils literal notranslate"><span class="pre">const</span></code>) angegeben, außerdem für jeden von ihnen der Standardfehler, die <span class="math notranslate nohighlight">\(t\)</span>-Werte und die <span class="math notranslate nohighlight">\(p\)</span>-Werte.</p></li>
</ul>
</div>
<div class="section" id="diagnostische-plots">
<h3>Diagnostische Plots<a class="headerlink" href="#diagnostische-plots" title="Permalink to this headline">¶</a></h3>
<p>Es ist wichtig zu wissen, dass Sie eine lineare Regressionsanalyse mit dem Softwarepaket Python oder einer anderen Statistiksoftware durchführen können, die eine Reihe von Zahlen, einschließlich eines <span class="math notranslate nohighlight">\(p\)</span>-Werts, ergibt, so dass Sie sofort feststellen können, ob die Ergebnisse signifikant waren (oder nicht). Sind wir mit der Angabe der Signifikanz der Ergebnisse fertig?</p>
<p>Nehmen wir einen sehr berühmten Datensatz, das so genannte <a href="https://de.wikipedia.org/wiki/Anscombe-Quartett">Anscombe-Quartett</a>. Das Anscombe-Quartett besteht aus vier Datensätzen und hat die folgende Form:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>x1</p></td>
<td><p>y1</p></td>
<td><p>x2</p></td>
<td><p>y2</p></td>
<td><p>x3</p></td>
<td><p>y3</p></td>
<td><p>x4</p></td>
<td><p>y4</p></td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><p>8,04</p></td>
<td><p>10</p></td>
<td><p>9,14</p></td>
<td><p>10</p></td>
<td><p>7,46</p></td>
<td><p>8</p></td>
<td><p>6,58</p></td>
</tr>
<tr class="row-even"><td><p>8</p></td>
<td><p>6,95</p></td>
<td><p>8</p></td>
<td><p>8,14</p></td>
<td><p>8</p></td>
<td><p>6,77</p></td>
<td><p>8</p></td>
<td><p>5,76</p></td>
</tr>
<tr class="row-odd"><td><p>13</p></td>
<td><p>7,58</p></td>
<td><p>13</p></td>
<td><p>8,74</p></td>
<td><p>13</p></td>
<td><p>12,74</p></td>
<td><p>8</p></td>
<td><p>7,71</p></td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><p>8,81</p></td>
<td><p>9</p></td>
<td><p>8,77</p></td>
<td><p>9</p></td>
<td><p>7,11</p></td>
<td><p>8</p></td>
<td><p>8,84</p></td>
</tr>
<tr class="row-odd"><td><p>11</p></td>
<td><p>8,33</p></td>
<td><p>11</p></td>
<td><p>9,26</p></td>
<td><p>11</p></td>
<td><p>7,81</p></td>
<td><p>8</p></td>
<td><p>8,47</p></td>
</tr>
<tr class="row-even"><td><p>14</p></td>
<td><p>9,96</p></td>
<td><p>14</p></td>
<td><p>8,1</p></td>
<td><p>14</p></td>
<td><p>8,84</p></td>
<td><p>8</p></td>
<td><p>7,04</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p>7,24</p></td>
<td><p>6</p></td>
<td><p>6,13</p></td>
<td><p>6</p></td>
<td><p>6,08</p></td>
<td><p>8</p></td>
<td><p>5,25</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>4,26</p></td>
<td><p>4</p></td>
<td><p>3,1</p></td>
<td><p>4</p></td>
<td><p>5,39</p></td>
<td><p>19</p></td>
<td><p>12,5</p></td>
</tr>
<tr class="row-odd"><td><p>12</p></td>
<td><p>10,84</p></td>
<td><p>12</p></td>
<td><p>9,13</p></td>
<td><p>12</p></td>
<td><p>8,15</p></td>
<td><p>8</p></td>
<td><p>5,56</p></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p>4,82</p></td>
<td><p>7</p></td>
<td><p>7,26</p></td>
<td><p>7</p></td>
<td><p>6,42</p></td>
<td><p>8</p></td>
<td><p>7,91</p></td>
</tr>
<tr class="row-odd"><td><p>5</p></td>
<td><p>5,68</p></td>
<td><p>5</p></td>
<td><p>4,74</p></td>
<td><p>5</p></td>
<td><p>5,73</p></td>
<td><p>8</p></td>
<td><p>6,89</p></td>
</tr>
</tbody>
</table>
<p>Das Anscombe-Quartett wird oft verwendet um die Unterschiede zwischen grafischer und statistischer Auswertung hervorzuheben. Wir geben den Datensatz in Python ein.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">y1</span> <span class="o">=</span> <span class="p">[</span><span class="mf">8.04</span><span class="p">,</span> <span class="mf">6.95</span><span class="p">,</span> <span class="mf">7.58</span><span class="p">,</span> <span class="mf">8.81</span><span class="p">,</span> <span class="mf">8.33</span><span class="p">,</span> <span class="mf">9.96</span><span class="p">,</span> <span class="mf">7.24</span><span class="p">,</span> <span class="mf">4.26</span><span class="p">,</span> <span class="mf">10.84</span><span class="p">,</span> <span class="mf">4.82</span><span class="p">,</span> <span class="mf">5.68</span><span class="p">]</span>

<span class="n">x2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">y2</span> <span class="o">=</span> <span class="p">[</span><span class="mf">9.14</span><span class="p">,</span> <span class="mf">8.14</span><span class="p">,</span> <span class="mf">8.74</span><span class="p">,</span> <span class="mf">8.77</span><span class="p">,</span> <span class="mf">9.26</span><span class="p">,</span> <span class="mf">8.10</span><span class="p">,</span> <span class="mf">6.13</span><span class="p">,</span> <span class="mf">3.10</span><span class="p">,</span> <span class="mf">9.13</span><span class="p">,</span> <span class="mf">7.26</span><span class="p">,</span> <span class="mf">4.74</span><span class="p">]</span>

<span class="n">x3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">y3</span> <span class="o">=</span> <span class="p">[</span><span class="mf">7.46</span><span class="p">,</span> <span class="mf">6.77</span><span class="p">,</span> <span class="mf">12.74</span><span class="p">,</span> <span class="mf">7.11</span><span class="p">,</span> <span class="mf">7.81</span><span class="p">,</span> <span class="mf">8.84</span><span class="p">,</span> <span class="mf">6.08</span><span class="p">,</span> <span class="mf">5.39</span><span class="p">,</span> <span class="mf">8.15</span><span class="p">,</span> <span class="mf">6.42</span><span class="p">,</span> <span class="mf">5.73</span><span class="p">]</span>

<span class="n">x4</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="n">y4</span> <span class="o">=</span> <span class="p">[</span><span class="mf">6.58</span><span class="p">,</span> <span class="mf">5.76</span><span class="p">,</span> <span class="mf">7.71</span><span class="p">,</span> <span class="mf">8.84</span><span class="p">,</span> <span class="mf">8.47</span><span class="p">,</span> <span class="mf">7.04</span><span class="p">,</span> <span class="mf">5.25</span><span class="p">,</span> <span class="mf">12.50</span><span class="p">,</span> <span class="mf">5.56</span><span class="p">,</span> <span class="mf">7.91</span><span class="p">,</span> <span class="mf">6.89</span><span class="p">]</span>

<span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">,</span> <span class="n">x4</span><span class="p">]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="n">y1</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">y3</span><span class="p">,</span> <span class="n">y4</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Nun berechnen wir einige deskriptive statistische Maße für jedes der vier <span class="math notranslate nohighlight">\((x,y)\)</span>-Paare. Zunächst berechnen wir den Mittelwert für jedes einzelne <span class="math notranslate nohighlight">\(x\)</span> und <span class="math notranslate nohighlight">\(y\)</span> im Datensatz.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">e</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mean x</span><span class="si">{</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2"> | mean y</span><span class="si">{</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">),</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mean x1: 9.0 | mean y1: 7.501
mean x2: 9.0 | mean y2: 7.501
mean x3: 9.0 | mean y3: 7.5
mean x4: 9.0 | mean y4: 7.501
</pre></div>
</div>
</div>
</div>
<p>Die Werte stimmen entweder perfekt überein oder liegen sehr nahe beieinander!!</p>
<p>Jetzt berechnen wir die Varianz jedes <span class="math notranslate nohighlight">\((x,y)\)</span> Paares.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">e</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;variance x</span><span class="si">{</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2"> | variance y</span><span class="si">{</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">y</span><span class="p">),</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>variance x1: 10.0 | variance y1: 3.752
variance x2: 10.0 | variance y2: 3.752
variance x3: 10.0 | variance y3: 3.748
variance x4: 10.0 | variance y4: 3.748
</pre></div>
</div>
</div>
</div>
<p>Sie sind zwar nicht exakt gleich, aber definitiv sehr nahe beieinander. Schließlich erstellen wir mit der Funktion <code class="docutils literal notranslate"><span class="pre">linregress()</span></code> ein lineares Modell für jede Teilmenge und berechnen die Koeffizienten des Modells und <span class="math notranslate nohighlight">\(R^2\)</span>, das Bestimmtheitsmaß.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">e</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)):</span>
    <span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">std_err</span> <span class="o">=</span> <span class="n">linregress</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">x + </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">intercept</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">,  p-value: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">p_value</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span><span class="si">}</span><span class="s2">, Pearson correlation coefficient: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">r_value</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">, Standard error of the estimated slope: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">std_err</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1: 0.5x + 3.0,  p-value: 0.00217, Pearson correlation coefficient: 0.816, Standard error of the estimated slope: 0.1179
2: 0.5x + 3.0,  p-value: 0.00218, Pearson correlation coefficient: 0.816, Standard error of the estimated slope: 0.118
3: 0.5x + 3.0,  p-value: 0.00218, Pearson correlation coefficient: 0.816, Standard error of the estimated slope: 0.1179
4: 0.5x + 3.0,  p-value: 0.00216, Pearson correlation coefficient: 0.817, Standard error of the estimated slope: 0.1178
</pre></div>
</div>
</div>
</div>
<p>Erstaunlich! Sie sind fast identisch! Und jetzt <span class="math notranslate nohighlight">\(R^2\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">e</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">linregress</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;r2: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">r_value</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>r2: 0.667
r2: 0.666
r2: 0.666
r2: 0.667
</pre></div>
</div>
</div>
</div>
<p>Wow, was für eine Analyse! Wir haben eine Menge verschiedener statistischer Methoden auf die vier Datensätze angewandt, und ehrlich gesagt, sie sehen einander sehr ähnlich.</p>
<p>Sind wir jetzt mit unserer Analyse fertig? Nein, noch nicht! Egal was wir tun, wir sollten immer überprüfen, ob das Modell für die Daten gut funktioniert. Eine einfache Möglichkeit, dies zu tun, ist die Visualisierung der Daten. Lassen Sie uns den Anscombe-Datensatz einschließlich der Regressionslinie grafisch darstellen.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>
<span class="n">xaxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="k">for</span> <span class="n">e</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)):</span>
    <span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">linregress</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">regline</span> <span class="o">=</span> <span class="n">intercept</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">xaxis</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="n">regline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Anscombe&#39;s Datensatz #</span><span class="si">{</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;y=</span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">intercept</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">+</span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">x&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/01_Lineare_Regression_110_0.png" src="../_images/01_Lineare_Regression_110_0.png" />
</div>
</div>
<p>Was für eine Überraschung! Das wichtigste Ergebnis der Übung ist die Erkenntnis, dass wir auf viele verschiedene Arten prüfen müssen, ob ein Modell für Daten gut funktioniert. Wir achten auf Regressionsergebnisse wie Steigungskoeffizienten, <span class="math notranslate nohighlight">\(p\)</span>-Werte oder <span class="math notranslate nohighlight">\(R^2\)</span>, die uns sagen, wie gut ein Modell die gegebenen Daten darstellt. Das ist jedoch nicht die ganze Geschichte. Wir müssen auch visuelle Diagnosen anwenden. Die visuelle Inspektion hilft bei der Bewertung, ob die Annahmen der linearen Regression erfüllt sind, oder bei der Ermittlung von <a href="https://de.wikipedia.org/wiki/Ausrei%C3%9Fer">Ausreißern</a> und/oder <a href="https://ethz.ch/content/dam/ethz/special-interest/math/statistics/sfs/Education/Advanced%20Studies%20in%20Applied%20Statistics/course-material-1921/Regression/reg-script-full.pdf">statistisch bedeutsame Beobachtungen</a> und so genannten <a href="https://de.wikipedia.org/wiki/Pr%C3%A4diktionsmatrix#Hebelwerte">Hebelwerte</a>, die das numerische Ergebnis der Regressionsanalyse beeinflussen.</p>
</div>
<div class="section" id="analyse-der-residuen">
<h3>Analyse der Residuen<a class="headerlink" href="#analyse-der-residuen" title="Permalink to this headline">¶</a></h3>
<p>Ein <a href="https://de.wikipedia.org/wiki/St%C3%B6rgr%C3%B6%C3%9Fe_und_Residuum">Residuum</a> eines beobachteten Wertes ist die Differenz zwischen dem beobachteten Wert und dem geschätzten Wert <span class="math notranslate nohighlight">\((y_i- \hat y_i)\)</span>. Es handelt sich um die Residuen, die nach der Anpassung eines Modells an die Daten übrig bleiben. Die <strong>Summe der quadrierten Vorhersagefehler</strong> (<span class="math notranslate nohighlight">\(SSE\)</span>), auch bekannt als die <strong>Summe der quadrierten Residuen</strong> oder die <strong>Fehlersumme der Quadrate</strong>, ist ein Indikator dafür, wie gut ein Modell die Daten darstellt.</p>
<p>Wenn die absoluten Residuen, definiert für die Beobachtung <span class="math notranslate nohighlight">\(x_i\)</span> als <span class="math notranslate nohighlight">\(e_i=y_i- \hat y_i\)</span> definiert sind, ungewöhnlich groß sind, kann es sein, dass die Beobachtung aus einer anderen Grundgesamtheit stammt oder dass bei der Durchführung oder Aufzeichnung der Beobachtung ein Fehler aufgetreten ist.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">xaxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;C1&quot;</span><span class="p">,</span> <span class="s2">&quot;C3&quot;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">e</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">((</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="mi">2</span><span class="p">]))):</span>
    <span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">linregress</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">regline</span> <span class="o">=</span> <span class="n">intercept</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">xaxis</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="n">regline</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">e</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">e</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">_x</span><span class="p">,</span> <span class="n">_y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">intercept</span> <span class="o">+</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">_x</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">((</span><span class="n">_x</span><span class="p">,</span> <span class="n">_x</span><span class="p">),</span> <span class="p">(</span><span class="n">_y</span><span class="p">,</span> <span class="n">yhat</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Anscombe&#39;s Datensatz #</span><span class="si">{</span><span class="n">colors</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/01_Lineare_Regression_114_0.png" src="../_images/01_Lineare_Regression_114_0.png" />
</div>
</div>
<p>Die beiden obigen Diagramme zeigen, dass ein Datenpunkt in Anscombes Datensatz Nr. <span class="math notranslate nohighlight">\(3\)</span> (rechtes Diagramm) ein ungewöhnlich großes Residuum aufweist. Ein solcher Datenpunkt erfordert besondere Aufmerksamkeit, da er die Regressionsanalyse beeinflusst. Es gibt keine allgemeingültige Regel, wie mit Ausreißern umzugehen ist, aber je nach den Fachkenntnissen des Forschers kann es Fälle geben, in denen man beschließt, einen solchen Ausreißer aus der Analyse auszuschließen.</p>
<p>Darüber hinaus können wir die Residuen analysieren, um zu prüfen, ob die Annahmen der linearen Regression erfüllt sind. Regressionsresiduen sollten annähernd normalverteilt sein, d. h. die Regression sollte die Struktur erklären, und was übrig bleibt, sollte nur Rauschen sein, das durch Messfehler oder viele kleine unkorrelierte Faktoren verursacht wird. Die Normalität der Residuen kann grafisch überprüft werden, indem man die Residuen gegen die Werte der Prädiktorvariablen aufträgt. In einem solchen <strong>Residuen-Plot</strong> sollten die Residuen zufällig um <span class="math notranslate nohighlight">\(0\)</span> streuen
und die Variation um <span class="math notranslate nohighlight">\(0\)</span> sollte gleich sein.</p>
<p>Vor der Darstellung der Residuen ist es üblich, die Residuen zu standardisieren. Python bietet die Möglichkeit mit <code class="docutils literal notranslate"><span class="pre">get_influence()</span></code> auf die standardisierten Residuen zuzugreifen (<code class="docutils literal notranslate"><span class="pre">influence</span> <span class="pre">=</span> <span class="pre">model.get_influence()</span> </code> und <code class="docutils literal notranslate"><span class="pre">standardized_residuals</span> <span class="pre">=</span> <span class="pre">influence.resid_studentized_internal</span></code>) und alternativ kann man mit <code class="docutils literal notranslate"><span class="pre">stud_res</span> <span class="pre">=</span> <span class="pre">model.outlier_test()</span></code> die studentisierten Residuen (<span id="id4">Fahrmeir <em>et al.</em> [<a class="reference internal" href="../Literaturverzeichnis.html#id3" title="Ludwig Fahrmeir, Christian Heumann, Rita Künstler, Iris Pigeot, and Gerhard Tutz. Statistik: Der weg zur Datenanalyse. Springer-Verlag, 2016.">2016</a>]</span> s.152) berechnen.</p>
<p>Wenn die Annahmen für Regressionsschlussfolgerungen erfüllt sind, sollten die folgenden zwei Bedingungen gelten (<span id="id5">Fahrmeir <em>et al.</em> [<a class="reference internal" href="../Literaturverzeichnis.html#id3" title="Ludwig Fahrmeir, Christian Heumann, Rita Künstler, Iris Pigeot, and Gerhard Tutz. Statistik: Der weg zur Datenanalyse. Springer-Verlag, 2016.">2016</a>]</span> s.443):</p>
<ul class="simple">
<li><p>Eine Darstellung der Residuen (Residuenplot) gegen die Werte der Prädiktorvariablen sollte ungefähr in ein horizontales Band fallen, das um die <span class="math notranslate nohighlight">\(x\)</span>-Achse zentriert und symmetrisch ist.</p></li>
<li><p>Eine Normalwahrscheinlichkeitsdarstellung der Residuen sollte in etwa linear sein.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">toy_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">toy1_y</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">toy_x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">toy2_y</span> <span class="o">=</span> <span class="n">toy_x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">eps</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">*</span> <span class="p">(</span><span class="n">toy_x</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
<span class="n">toy3_y</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">toy_x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

<span class="n">toys</span> <span class="o">=</span> <span class="p">[</span><span class="n">toy1_y</span><span class="p">,</span> <span class="n">toy2_y</span><span class="p">,</span> <span class="n">toy3_y</span><span class="p">]</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Keine Verletzung&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Verletzung der Linearität&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Verletzung der konstanten Standardabweichung (Heteroskedastizität)&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">toy_x</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">toys</span><span class="p">))</span>
<span class="k">for</span> <span class="n">e</span><span class="p">,</span> <span class="n">toy</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">toys</span><span class="p">):</span>

    <span class="n">_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">toy</span><span class="p">,</span> <span class="n">toy_x</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="n">influence</span> <span class="o">=</span> <span class="n">_model</span><span class="o">.</span><span class="n">get_influence</span><span class="p">()</span>
    <span class="n">standardized_residuals</span> <span class="o">=</span> <span class="n">influence</span><span class="o">.</span><span class="n">resid_studentized_internal</span>

    <span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">toy_x</span><span class="p">,</span> <span class="n">standardized_residuals</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">titles</span><span class="p">[</span><span class="n">e</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">4.5</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Residuen-Plots&quot;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">28</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/01_Lineare_Regression_116_0.png" src="../_images/01_Lineare_Regression_116_0.png" />
</div>
</div>
<p>Nur in der obersten Grafik sind die Residuen relativ gut um den Nullpunkt verteilt, während dies in den beiden unteren Grafiken nicht der Fall ist, was darauf hindeutet, dass die linearen Modellannahmen für dieses Modell nicht erfüllt sind.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">toys</span> <span class="o">=</span> <span class="p">[</span><span class="n">toy1_y</span><span class="p">,</span> <span class="n">toy2_y</span><span class="p">,</span> <span class="n">toy3_y</span><span class="p">]</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Keine Verletzung&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Verletzung der Linearität&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Heteroskedastizität&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">toys</span><span class="p">))</span>
<span class="k">for</span> <span class="n">e</span><span class="p">,</span> <span class="n">toy</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">toys</span><span class="p">):</span>
    <span class="n">_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">toy</span><span class="p">,</span> <span class="n">toy_x</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="n">influence</span> <span class="o">=</span> <span class="n">_model</span><span class="o">.</span><span class="n">get_influence</span><span class="p">()</span>
    <span class="n">standardized_residuals</span> <span class="o">=</span> <span class="n">influence</span><span class="o">.</span><span class="n">resid_studentized_internal</span>
    <span class="n">sm</span><span class="o">.</span><span class="n">qqplot</span><span class="p">(</span><span class="n">standardized_residuals</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="s2">&quot;s&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">e</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">titles</span><span class="p">[</span><span class="n">e</span><span class="p">])</span>

<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Q-Q-Diagramm&quot;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">28</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/01_Lineare_Regression_118_0.png" src="../_images/01_Lineare_Regression_118_0.png" />
</div>
</div>
<p>Die Normalwahrscheinlichkeitsdiagramme, die oft als <a href="https://de.wikipedia.org/wiki/Quantil-Quantil-Diagramm">Q-Q-Diagramme</a> bezeichnet werden, zeigen, dass nur im linken Diagramm die Datenpunkte in etwa auf eine gerade Linie fallen. Dies ist bei den anderen Diagrammen nicht der Fall, was darauf hindeutet, dass die Annahmen des linearen Modells nicht erfüllt sind.</p>
</div>
<div class="section" id="ausreiszer-und-einfluszreiche-beobachtungen">
<h3>Ausreißer und einflußreiche Beobachtungen<a class="headerlink" href="#ausreiszer-und-einfluszreiche-beobachtungen" title="Permalink to this headline">¶</a></h3>
<p><strong>Ausreißer</strong> sind Punkte, die aus der Wolke der Datenpunkte herausfallen. Ausreißer, die horizontal von der Mitte der Wolke wegfallen und die Neigung der Regressionslinie nicht beeinflussen, werden als <strong>Leverage-Werte</strong> (Hebelwerte) bezeichnet. Ausreißer, die die Steigung der Regressionsgeraden tatsächlich beeinflussen, werden als <strong>einflußreiche Beobachtungen</strong> bezeichnet, bei denen es sich in der Regel um hohe Leverage-Punkte handelt.</p>
<p>Wir wollen einen Beispielsdatensatz erstellen, um das Konzept der statistisch bedeutsamen Beobachtungen zu untersuchen.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">110</span><span class="p">)</span>  <span class="c1"># seede zufallswerte</span>

<span class="c1"># Erzeuge Zufallswerte</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">beta0</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">beta1</span> <span class="o">=</span> <span class="mf">2.5</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">beta0</span> <span class="o">+</span> <span class="n">beta1</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>  <span class="c1"># add random noise</span>

<span class="c1"># Erzeuge Hebelwerte</span>
<span class="n">n_lev</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="mf">0.05</span><span class="p">)</span>
<span class="n">x_lev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">n_lev</span><span class="p">)</span>
<span class="n">y_lev</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">beta0</span><span class="o">**</span><span class="mf">1.5</span> <span class="o">+</span> <span class="n">beta1</span><span class="o">**</span><span class="mi">3</span> <span class="o">*</span> <span class="n">x_lev</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_lev</span><span class="p">)</span>
<span class="p">)</span>  <span class="c1"># add random noise</span>

<span class="c1"># Erzeuge einflußreiche Beobachtungen</span>
<span class="n">n_inf</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="mf">0.02</span><span class="p">)</span>
<span class="n">x_inf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">n_inf</span><span class="p">)</span>
<span class="n">y_inf</span> <span class="o">=</span> <span class="n">beta0</span> <span class="o">+</span> <span class="n">beta1</span><span class="o">**</span><span class="mf">2.5</span> <span class="o">*</span> <span class="n">x_inf</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_inf</span><span class="p">)</span>


<span class="c1"># Baue Datensätze</span>
<span class="n">x_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">x_inf</span><span class="p">,</span> <span class="n">x_lev</span><span class="p">])</span>
<span class="n">y_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">y_inf</span><span class="p">,</span> <span class="n">y_lev</span><span class="p">])</span>

<span class="c1"># Fitte lineares Modell</span>
<span class="n">base_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">lev_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">y_lev</span><span class="p">]),</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">x_lev</span><span class="p">])))</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">inf_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">y_inf</span><span class="p">]),</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">x_inf</span><span class="p">])))</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">full_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y_full</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">x_full</span><span class="p">))</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Datenpunkte ohne Ausreisser&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_lev</span><span class="p">,</span> <span class="n">y_lev</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Hebelpunkte&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_inf</span><span class="p">,</span> <span class="n">y_inf</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Aussreisser mit Einfluss&quot;</span><span class="p">)</span>

<span class="n">xaxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_model</span> <span class="ow">in</span> <span class="p">[</span><span class="n">base_model</span><span class="p">,</span> <span class="n">lev_model</span><span class="p">,</span> <span class="n">inf_model</span><span class="p">]:</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">xaxis</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">)</span>
<span class="n">pred_full</span> <span class="o">=</span> <span class="n">full_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">xaxis</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="n">pred_full</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(-1.65, 12.65, -23.52561113057294, 125.83725556438257)
</pre></div>
</div>
<img alt="../_images/01_Lineare_Regression_122_1.png" src="../_images/01_Lineare_Regression_122_1.png" />
</div>
</div>
<p>Die obige Abbildung zeigt deutlich die Auswirkungen der verschiedenen Arten von Ausreißern. Die blaue gestrichelte Linie zeigt die Regressionslinie ohne Ausreißer, die orange gestrichelte Linie zeigt die Regressionslinie, wenn die orangen Hebelpunkte enthalten sind, die grüne gestrichelte Linie zeigt die Regressionslinie, wenn die grünen Ausreisser enthalten sind, und die rote Linie zeigt die Regressionslinie, wenn alle Daten enthalten sind. Offensichtlich haben die grünen Punkte den größten Einfluss auf die Steigung der Regressionslinie!</p>
<div class="section" id="leverage">
<h4>Leverage<a class="headerlink" href="#leverage" title="Permalink to this headline">¶</a></h4>
<p>Die <a href="https://de.wikipedia.org/wiki/Pr%C3%A4diktionsmatrix#Hebelwerte">Leverage</a> einer Beobachtung zeigt an, ob sie das Regressionsmodell beeinflussen kann. Diese Beobachtungen sind nicht notwendigerweise ein Fehler, aber sie sollten identifiziert und überprüft werden. Die Leverage wird durch den <strong><span class="math notranslate nohighlight">\(H\)</span>-Wert</strong> gemessen, der den Gesamteinfluss einer einzelnen Beobachtung auf die Modellvorhersagen misst. Der <span class="math notranslate nohighlight">\(H\)</span>-Wert nimmt Werte zwischen <span class="math notranslate nohighlight">\(0\)</span> und <span class="math notranslate nohighlight">\(1\)</span> an. Ein Punkt mit einer Hebelwirkung von Null hat keinen Einfluss auf das Regressionsmodell. Je höher der <span class="math notranslate nohighlight">\(H\)</span>-Wert ist, desto größer ist der Einfluss des betreffenden Punktes auf das Regressionsmodell.</p>
</div>
<div class="section" id="cook-abstand">
<h4>Cook-Abstand<a class="headerlink" href="#cook-abstand" title="Permalink to this headline">¶</a></h4>
<p>Eine weitere Methode zur Erfassung einflussreicher Ausreißer ist der <a href="https://de.wikipedia.org/wiki/Cook-Abstand">Cook-Abstand</a>. Das Maß ist eine Kombination aus Leverage und Residuen der einzelnen Beobachtungen. Je höher die Hebelwirkung und der Rückstand, desto größer ist der Cook-Abstand. Normalerweise werden Punkte mit einem Cook-Abstand von mehr als <span class="math notranslate nohighlight">\(1\)</span> als einflussreich eingestuft. In Python wird der Cook-Abstand mit dem Attribut <code class="docutils literal notranslate"><span class="pre">cooks.distance</span></code> berechnet.</p>
</div>
<div class="section" id="andere-nutzliche-regressionsdiagnosen">
<h4>Andere nützliche Regressionsdiagnosen<a class="headerlink" href="#andere-nutzliche-regressionsdiagnosen" title="Permalink to this headline">¶</a></h4>
<p>Weitere nützliche Werkzeuge für die Regressionsanalysediagnose sind DFFITS (“difference in fit(s)”), die angibt, wie sehr eine Beobachtung den zugehörigen angepassten Wert beeinflusst, und die DFBETAS, die die Änderung der geschätzten Parameter angibt, wenn eine Beobachtung im Verhältnis zu ihrem Standardfehler ausgeschlossen wird.</p>
<p>In Paket statsmodels kann auf diese die genanten und weitere diagnostische Verfahren sehr leicht über die Methdode <code class="docutils literal notranslate"><span class="pre">get_influence().summary_frame()</span></code>zurückgegriffen werden.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">full_model</span><span class="o">.</span><span class="n">get_influence</span><span class="p">()</span><span class="o">.</span><span class="n">summary_frame</span><span class="p">()</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>dfb_const</th>
      <th>dfb_x1</th>
      <th>cooks_d</th>
      <th>standard_resid</th>
      <th>hat_diag</th>
      <th>dffits_internal</th>
      <th>student_resid</th>
      <th>dffits</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>17</th>
      <td>-0.008556</td>
      <td>-0.006683</td>
      <td>0.000378</td>
      <td>-0.274503</td>
      <td>0.009938</td>
      <td>-0.027502</td>
      <td>-0.273291</td>
      <td>-0.027380</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.000263</td>
      <td>0.009673</td>
      <td>0.000158</td>
      <td>0.152658</td>
      <td>0.013345</td>
      <td>0.017754</td>
      <td>0.151946</td>
      <td>0.017671</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.066637</td>
      <td>-0.022027</td>
      <td>0.004280</td>
      <td>0.924806</td>
      <td>0.009908</td>
      <td>0.092515</td>
      <td>0.924163</td>
      <td>0.092451</td>
    </tr>
    <tr>
      <th>86</th>
      <td>-0.075890</td>
      <td>0.031410</td>
      <td>0.004754</td>
      <td>-0.949855</td>
      <td>0.010429</td>
      <td>-0.097511</td>
      <td>-0.949408</td>
      <td>-0.097465</td>
    </tr>
    <tr>
      <th>39</th>
      <td>0.003107</td>
      <td>-0.002012</td>
      <td>0.000006</td>
      <td>0.027135</td>
      <td>0.014813</td>
      <td>0.003327</td>
      <td>0.027006</td>
      <td>0.003311</td>
    </tr>
    <tr>
      <th>82</th>
      <td>0.023955</td>
      <td>-0.091890</td>
      <td>0.009254</td>
      <td>-1.028980</td>
      <td>0.017179</td>
      <td>-0.136041</td>
      <td>-1.029271</td>
      <td>-0.136080</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.027092</td>
      <td>-0.097669</td>
      <td>0.010127</td>
      <td>-1.061836</td>
      <td>0.017647</td>
      <td>-0.142317</td>
      <td>-1.062488</td>
      <td>-0.142404</td>
    </tr>
    <tr>
      <th>36</th>
      <td>0.040591</td>
      <td>-0.033427</td>
      <td>0.000833</td>
      <td>0.236372</td>
      <td>0.028942</td>
      <td>0.040807</td>
      <td>0.235306</td>
      <td>0.040623</td>
    </tr>
    <tr>
      <th>64</th>
      <td>-0.068953</td>
      <td>0.023327</td>
      <td>0.004514</td>
      <td>-0.948047</td>
      <td>0.009946</td>
      <td>-0.095021</td>
      <td>-0.947586</td>
      <td>-0.094975</td>
    </tr>
    <tr>
      <th>69</th>
      <td>0.009371</td>
      <td>-0.006311</td>
      <td>0.000049</td>
      <td>0.077862</td>
      <td>0.015872</td>
      <td>0.009888</td>
      <td>0.077493</td>
      <td>0.009841</td>
    </tr>
    <tr>
      <th>47</th>
      <td>0.039709</td>
      <td>-0.028573</td>
      <td>0.000839</td>
      <td>0.299574</td>
      <td>0.018354</td>
      <td>0.040963</td>
      <td>0.298272</td>
      <td>0.040785</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.125702</td>
      <td>-0.105563</td>
      <td>0.007940</td>
      <td>0.696475</td>
      <td>0.031701</td>
      <td>0.126018</td>
      <td>0.694757</td>
      <td>0.125708</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Ebenso stehen Visualisierungsmethoden zur Auswahl.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">graphics</span><span class="o">.</span><span class="n">influence_plot</span><span class="p">(</span><span class="n">full_model</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;cooks&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/01_Lineare_Regression_133_0.png" src="../_images/01_Lineare_Regression_133_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">graphics</span><span class="o">.</span><span class="n">influence_plot</span><span class="p">(</span><span class="n">full_model</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;DFFITS&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/01_Lineare_Regression_134_0.png" src="../_images/01_Lineare_Regression_134_0.png" />
</div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ixianslab/srh-data-science",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Kapitel08"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../Kapitel07/01_Analyse_der_Varianz_ANOVA.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Varianzanalyse - ANOVA</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="02_Polynomiale_Regression.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Polynomiale Regression</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By ixians<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>