
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>The Central Limit Theorem &#8212; Central Limit Theorem</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Getting started" href="getting_started.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/ixians.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Central Limit Theorem</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Welcome to the proof oc concept for the section Central Limit Theorem
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="getting_started.html">
   Getting started
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   The Central Limit Theorem
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/7_central_limit_theorem.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ixianslab/proof_of_concept_CLT"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/ixianslab/proof_of_concept_CLT/issues/new?title=Issue%20on%20page%20%2F7_central_limit_theorem.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/ixianslab/proof_of_concept_CLT/master?urlpath=tree/docs/7_central_limit_theorem.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-population-distribution">
   The Population Distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#population-statistics-and-sample-statistics">
   Population Statistics and Sample Statistics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-sampling-error">
   The Sampling Error
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-sampling-distribution">
   The Sampling Distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-standard-error">
   The Standard Error
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sampling-from-a-normally-distributed-population">
   Sampling from a Normally Distributed Population
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#shape-of-the-sampling-distribution">
     Shape of the Sampling Distribution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Sampling from a Normally Distributed Population
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sampling-from-a-population-that-is-not-normally-distributed">
   Sampling from a Population that is not Normally Distributed
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Shape of the Sampling Distribution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sampling-from-a-population-which-is-not-normally-distributed">
     Sampling from a population which is not normally distributed
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>The Central Limit Theorem</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-population-distribution">
   The Population Distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#population-statistics-and-sample-statistics">
   Population Statistics and Sample Statistics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-sampling-error">
   The Sampling Error
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-sampling-distribution">
   The Sampling Distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-standard-error">
   The Standard Error
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sampling-from-a-normally-distributed-population">
   Sampling from a Normally Distributed Population
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#shape-of-the-sampling-distribution">
     Shape of the Sampling Distribution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Sampling from a Normally Distributed Population
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sampling-from-a-population-that-is-not-normally-distributed">
   Sampling from a Population that is not Normally Distributed
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Shape of the Sampling Distribution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sampling-from-a-population-which-is-not-normally-distributed">
     Sampling from a population which is not normally distributed
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="c1"># Load the &quot;autoreload&quot; extension</span>
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="c1"># always reload modules</span>
<span class="o">%</span><span class="k">autoreload</span> 2
<span class="c1"># black formatter for jupyter notebooks </span>
<span class="c1">#%load_ext nb_black</span>
<span class="c1"># black formatter for jupyter lab</span>
<span class="o">%</span><span class="k">load_ext</span> lab_black

<span class="o">%</span><span class="k">run</span> ../src/notebook_env.py
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---------------------------------
Working on the host: Joachims-MacBook-Pro.local

---------------------------------
Python version: 3.10.2 | packaged by conda-forge | (main, Feb  1 2022, 19:30:18) [Clang 11.1.0 ]

---------------------------------
Python interpreter: /opt/miniconda3/envs/srh-poc/bin/python

---------------------------------
Root (ROOT) directory is set to /Users/jokr/Documents/ixians_UG/Project_SRH/proof_of_concept
</pre></div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="the-central-limit-theorem">
<h1>The Central Limit Theorem<a class="headerlink" href="#the-central-limit-theorem" title="Permalink to this headline">¶</a></h1>
<p><strong>Import modules</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<p>The <strong>central limit theorem</strong> is one of the most useful concepts in statistics. The theorem is all about about drawing samples of a finite size <span class="math notranslate nohighlight">\(n\)</span> from a population. The  theorem states that  if one collects samples of a large enough sample size <span class="math notranslate nohighlight">\(n\)</span>, and calculates each sample’s mean (or sum), the shape of the histogram of those means (or sums) approximate a normal bell shape. The usefulness of the central limit theorem is due to the fact, that it <strong>it does not matter what the distribution of the original population is, the distribution of sample means and the sums tend to follow the normal distribution.</strong></p>
<div class="section" id="the-population-distribution">
<h2>The Population Distribution<a class="headerlink" href="#the-population-distribution" title="Permalink to this headline">¶</a></h2>
<p>The <strong>population distribution</strong> is the probability distribution derived from the knowledge of all elements of a population. We know that depending on the population of interest the random variable of interest may be a discrete variable, is to say a variable that, at least in principle is countable, or the random variable of interest may be a continuous variable, and thus a variable that can take any value within a given interval. Both, the discrete and the continuous probability distribution may be described by statistical parameters, such as the mean, the standard deviation, the median, the mode, among others. These parameters describing the population are, however, <strong>always constant</strong>, because the population is the set of all elements and thus population statistics do not change. For example, for any population data set, there is <strong>only one value</strong> of the population mean, <strong>one value</strong> for the standard deviation and so on.</p>
</div>
<div class="section" id="population-statistics-and-sample-statistics">
<h2>Population Statistics and Sample Statistics<a class="headerlink" href="#population-statistics-and-sample-statistics" title="Permalink to this headline">¶</a></h2>
<p>Let us consider a simple example of a small discrete population consisting of the first ten integers <span class="math notranslate nohighlight">\(\{1,2,3,4,5,6,7,8,9,10 \}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">population</span>  <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">]</span>

<span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">population</span><span class="p">)</span>

<span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5.5 3.0276503540974917
</pre></div>
</div>
</div>
</div>
<p>The population mean, denoted by <span class="math notranslate nohighlight">\(\mu\)</span> and the population standard deviation, denoted by <span class="math notranslate nohighlight">\(\sigma\)</span> is <span class="math notranslate nohighlight">\(5.5\)</span> and approximately {mean} <span class="math notranslate nohighlight">\(3.028\)</span>, respectively. It is important to realize, that these parameters, the population parameters will not change! They are fixed.</p>
<p>Let us now take a random sample without replacement of size <span class="math notranslate nohighlight">\(n=3\)</span> from this population.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">my_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">my_sample</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([9, 4, 8])
</pre></div>
</div>
</div>
</div>
<p>Now we caculate the mean and the standard deviation of the given sample. However, this time, as we refer to a particular sample, we call the statistical parameter <strong>sample statistic</strong> or if we relate to the distribution of values (elements) <strong>sample distribution</strong>. To make this more explicit, the sample mean is denominated as <span class="math notranslate nohighlight">\(\bar{x}\)</span> and the sample standard deviation as <span class="math notranslate nohighlight">\(s\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_bar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">my_sample</span><span class="p">)</span>

<span class="n">s_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">my_sample</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">x_bar</span><span class="p">,</span> <span class="n">s_x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>7.0 2.160246899469287
</pre></div>
</div>
</div>
</div>
<p>Note that depending on the actual elements in the sample, the sample statistic will change from sample to sample.</p>
</div>
<div class="section" id="the-sampling-error">
<h2>The Sampling Error<a class="headerlink" href="#the-sampling-error" title="Permalink to this headline">¶</a></h2>
<p>Let us repeat the sampling process from the previous section for <span class="math notranslate nohighlight">\(5\)</span> times, store the results in the variable <mark> my_experiment </mark> and in addition print out the mean, <span class="math notranslate nohighlight">\(\bar{x}\)</span> for each particular sample.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">population</span>  <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">]</span>

<span class="n">my_experiment</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">my_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">mean</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">my_sample</span><span class="p">)</span>
    <span class="n">my_experiment</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sample number </span><span class="si">{0}</span><span class="s1"> has a mean of </span><span class="si">{1}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">mean</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample number 1 has a mean of 5.0
Sample number 2 has a mean of 6.666666666666667
Sample number 3 has a mean of 5.333333333333333
Sample number 4 has a mean of 4.666666666666667
Sample number 5 has a mean of 3.6666666666666665
</pre></div>
</div>
</div>
</div>
<p>Obviously, different sample (of the same length) selected from the same population yield different sample statistics because they contain different elements. Moreover, any sample statistics obtained from any sample, such as the sample mean <span class="math notranslate nohighlight">\(\bar{x}\)</span>, will be different from the result obtained from the corresponding population, the population mean, <span class="math notranslate nohighlight">\(\mu\)</span>. The difference between the value of a sample statistic obtained from a sample and the value of the corresponding population parameter obtained from the population is called the <strong>sampling error</strong>. In the case of the mean, the sampling error can be written as</p>
<div class="math notranslate nohighlight">
\[ \text{Sampling error} = \bar{x} - \mu\]</div>
<p>Due to the nature of random sampling, and thus due to the process of drawing a set of values from the population, the resulting sampling error occurs due to chance, or in other words, the sampling error is a a random variable. However, one should note that besides the described randomness there are other sources of error. These errors are often related to the data generation process and are subsumed under the term non-sampling error. Such errors are introduced by for example human handling of the data, calibration errors of the measuring devices, among others.</p>
<p>In order to gain some intuition on the nature of the sampling error we conduct an experiment. For this experiment the population of interest consists of the first <span class="math notranslate nohighlight">\(100\)</span> integers <span class="math notranslate nohighlight">\(\{1,2,3,\dots,100 \}\)</span>. We want to analyse the effect of the sample size, <span class="math notranslate nohighlight">\(n\)</span>, on the sampling error. For the sake of simplicity we choose the sample mean as the statistic of interest. For a sufficient large number of trials (<mark> trials = 1000 </mark>) we calculate the sampling error for samples of size <span class="math notranslate nohighlight">\(n=10,25,50,75\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">population</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">101</span><span class="p">))</span>

<span class="n">mean_pop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">population</span><span class="p">)</span>

<span class="n">error_sample_10</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">error_sample_25</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">error_sample_50</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">error_sample_100</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># we do 1000 trials</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1001</span><span class="p">):</span>
    <span class="n">my_sample_10</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">my_sample_25</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
    <span class="n">my_sample_50</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">my_sample_100</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    
    <span class="n">mean_10</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">my_sample_10</span><span class="p">)</span>
    <span class="n">mean_25</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">my_sample_25</span><span class="p">)</span>
    <span class="n">mean_50</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">my_sample_50</span><span class="p">)</span>
    <span class="n">mean_100</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">my_sample_100</span><span class="p">)</span>
    
    <span class="n">error_sample_10</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">mean_10</span><span class="o">-</span> <span class="n">mean_pop</span><span class="p">))</span>
    <span class="n">error_sample_25</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">mean_25</span><span class="o">-</span> <span class="n">mean_pop</span><span class="p">))</span>
    <span class="n">error_sample_50</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">mean_50</span><span class="o">-</span> <span class="n">mean_pop</span><span class="p">))</span>
    <span class="n">error_sample_100</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">mean_100</span><span class="o">-</span> <span class="n">mean_pop</span><span class="p">))</span>
    
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sampling Error, n=10: &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">error_sample_10</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sampling Error, n=25: &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">error_sample_25</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sampling Error, n=50: &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">error_sample_50</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sampling Error, n=100: &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">error_sample_100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling Error, n=10:  7.2839
Sampling Error, n=25:  4.7364
Sampling Error, n=50:  3.1267199999999997
Sampling Error, n=100:  2.35879
</pre></div>
</div>
</div>
</div>
<p>Based on the experiment from above, we may conclude, that the large the sample size, the smaller is the sampling error. Or in other words, by increasing the sample size the sample mean, <span class="math notranslate nohighlight">\(\bar{x}\)</span> approximate the population mean, <span class="math notranslate nohighlight">\(\mu\)</span>. This is an important insight, which will be discussed in more details in the section of <em>Inferential Statistics</em>.</p>
</div>
<div class="section" id="the-sampling-distribution">
<h2>The Sampling Distribution<a class="headerlink" href="#the-sampling-distribution" title="Permalink to this headline">¶</a></h2>
<p>Based upon our intuition of randomness in the sampling process, we introduce the <strong>Sampling Distribution</strong>. The sampling distribution is a distribution of a sample statistic. Often the name of the computed statistic is added as part of the title. For example, if the computed statistic was the sample mean, the sampling distribution would be titled <strong>the sampling distribution of the sample mean</strong>.</p>
<p>Let us recall the simple example from the previous section, where the population is represented by the first <span class="math notranslate nohighlight">\(100\)</span> integers <span class="math notranslate nohighlight">\(\{1,2,3,\dots,100 \}\)</span>. If we repeatedly sample from that population and compute each time the sample statistic (e.g. <span class="math notranslate nohighlight">\(\bar{x}\)</span> or <span class="math notranslate nohighlight">\(s\)</span>,…), <strong>the resulting distribution of sample statistics is a called the sampling distribution of that statistic</strong>.</p>
<p>Let us take repeatedly random samples <span class="math notranslate nohighlight">\((x)\)</span> without replacement of size <span class="math notranslate nohighlight">\(n=30\)</span> from the population.</p>
<p>The random sampling might generate sets that look like</p>
<div class="math notranslate nohighlight">
\[\{19, 79, 33, 38, 14, 67, 7, 9, 12, 27, 4, 89, 34, 77, 78, 32, 65, 10, 84, 64, 90, 55, 88, 56, 11, 80, 15, 5, 91, 54\}\]</div>
<p>or</p>
<div class="math notranslate nohighlight">
\[\{43, 52, 56, 8, 65, 60, 46, 15, 64, 19, 82, 91, 88, 1, 5, 9, 4, 92, 67, 36, 72, 31, 50, 96, 87, 6, 93, 84, 78, 16\}\]</div>
<p>…</p>
<p>For each sample we calculate a sample statistic. In this example we take the mean, <span class="math notranslate nohighlight">\(\bar{x}\)</span>, of each sample. However, please note that the sample statistic could be any descriptive statistic, such as the median, the standard deviation, a proportion, among others. Once we obtained the sample means for all samples. we list all their different values and number of their occurrences (frequencies) in order to obtain relative frequencies or <strong>empirical probabilities</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">population</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">101</span><span class="p">))</span>

<span class="n">mean_pop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">population</span><span class="p">)</span>

<span class="n">num_samples</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">1000</span><span class="p">,</span><span class="mi">3000</span><span class="p">]</span>

<span class="n">my_sample</span> <span class="o">=</span> <span class="p">[[],[],[],[],[],[]]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">6</span><span class="p">):</span>   
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
        <span class="n">mean_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
        <span class="n">my_sample</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_sample</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:(</span><span class="mi">10</span><span class="p">,</span><span class="mi">13</span><span class="p">)})</span>
    
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">my_sample</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;1 random samples&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">70</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">my_sample</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span><span class="mf">0.0</span><span class="p">})</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;10 random samples&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">70</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">my_sample</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span><span class="mf">0.0</span><span class="p">})</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;100 random samples&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">70</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">my_sample</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span><span class="mf">0.0</span><span class="p">})</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;500 random samples&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">70</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">my_sample</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span><span class="mf">0.0</span><span class="p">})</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;1000 random samples&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">70</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">my_sample</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span><span class="mf">0.0</span><span class="p">})</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;3000 random samples&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">70</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s1">&#39;always&#39;</span><span class="p">)</span>

<span class="k">pass</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/miniconda3/envs/srh-poc/lib/python3.10/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)
/opt/miniconda3/envs/srh-poc/lib/python3.10/site-packages/seaborn/distributions.py:316: UserWarning: Dataset has 0 variance; skipping density estimate. Pass `warn_singular=False` to disable this warning.
  warnings.warn(msg, UserWarning)
/opt/miniconda3/envs/srh-poc/lib/python3.10/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)
/opt/miniconda3/envs/srh-poc/lib/python3.10/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)
/opt/miniconda3/envs/srh-poc/lib/python3.10/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)
/opt/miniconda3/envs/srh-poc/lib/python3.10/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/miniconda3/envs/srh-poc/lib/python3.10/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)
</pre></div>
</div>
<img alt="_images/7_central_limit_theorem_18_2.png" src="_images/7_central_limit_theorem_18_2.png" />
</div>
</div>
<p>The more often we take a sample the better the relative frequency distribution of the sample statistics approximates the sampling distribution. Or in other words, as the number of sample approaches infinity, the resulting frequency distribution will approach the sampling distribution. The <strong>sampling distribution of a statistic</strong> is a probability distribution of that statistic derived from all possible samples having the same size from the population. However, the sampling distribution should not be confused with a sample distribution: the latter describes the distribution of values (elements) in one particular sample.</p>
</div>
<div class="section" id="the-standard-error">
<h2>The Standard Error<a class="headerlink" href="#the-standard-error" title="Permalink to this headline">¶</a></h2>
<p>Just as the population distributions can be described with parameters, so can the sampling distribution. The expected value (mean) of any distribution can be represented by the symbol <span class="math notranslate nohighlight">\(\mu\)</span>. In case of the sampling distribution, the mean <span class="math notranslate nohighlight">\(\mu\)</span> is often written with a subscript to indicate which sampling distribution is being described. For example, the expected value of the sampling distribution of the mean is represented by the symbol <span class="math notranslate nohighlight">\(\mu_{\bar{x}}\)</span>. The value of <span class="math notranslate nohighlight">\(\mu_\bar{x}\)</span> can be thought as the theoretical mean of the distribution of sample means.</p>
<p>If we pick a large enough number of samples (of the same size) from a population and calculate their means, then the mean <span class="math notranslate nohighlight">\((\mu_{\bar{x}})\)</span> of all these sample means will approximate the mean <span class="math notranslate nohighlight">\((\mu)\)</span> of the population. That is why the sample mean <span class="math notranslate nohighlight">\(\bar{x}\)</span> is called an estimator of the population mean, <span class="math notranslate nohighlight">\(\mu\)</span>. Thus, the mean of the sampling distribution is equal to the mean of the population.</p>
<div class="math notranslate nohighlight">
\[\mu_{\bar{x}} = \mu\]</div>
<p>The standard deviation of a sampling distribution is given a special name, the <strong>standard error</strong>. The standard error of the sampling distribution of a statistic, denoted as <span class="math notranslate nohighlight">\(\sigma_{\bar{x}}\)</span>, describes the degree to which the computed statistic may be expected to differ from one another when calculated from a sample of similar size and selected from similar population models. The larger the standard error of a given statistic, the greater the differences between the computed statistics for the different samples.</p>
<p>However, please note that the standard error, <span class="math notranslate nohighlight">\(\sigma_{\bar{x}}\)</span> is not equal to the standard deviation, <span class="math notranslate nohighlight">\(\sigma\)</span>, of the population distribution (unless <span class="math notranslate nohighlight">\(n=1\)</span>). the standard error is equal to the standard deviation of the population divided by the square root of the sample size:</p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}}\]</div>
<p>This equation holds true only when the sampling is done either with replacement from a finite population or with or without replacement from an infinite population. Which corresponds to the condition that the sample size <span class="math notranslate nohighlight">\((n)\)</span> is small in comparison to the population size <span class="math notranslate nohighlight">\((N)\)</span>. The sample size is considered to be small compared to the population size if the sample size is equal to or less than <span class="math notranslate nohighlight">\(5\)</span>% of the population size that is, if</p>
<div class="math notranslate nohighlight">
\[\frac{n}{N} \leq 0.05\]</div>
<p>If this condition is not satisfied, the following equation is used to calculate <span class="math notranslate nohighlight">\(\sigma_{\bar{x}}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}} \sqrt{\frac{N-n}{N-1}}\]</div>
<p>In most practical applications, however, the sample size is small compared to the population size.</p>
</div>
<div class="section" id="sampling-from-a-normally-distributed-population">
<h2>Sampling from a Normally Distributed Population<a class="headerlink" href="#sampling-from-a-normally-distributed-population" title="Permalink to this headline">¶</a></h2>
<div class="section" id="shape-of-the-sampling-distribution">
<h3>Shape of the Sampling Distribution<a class="headerlink" href="#shape-of-the-sampling-distribution" title="Permalink to this headline">¶</a></h3>
<p>The shape of the sampling distribution relates to the following two cases:</p>
<ol class="simple">
<li><p>The population from which samples are drawn has a normal distribution.</p></li>
<li><p>The population from which samples are drawn does not have a normal distribution.</p></li>
</ol>
</div>
<div class="section" id="id1">
<h3>Sampling from a Normally Distributed Population<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>When the population from which samples are drawn is normally distributed with its mean equal to <span class="math notranslate nohighlight">\(\mu\)</span> and the standard deviation equal to <span class="math notranslate nohighlight">\(\sigma\)</span>, then:</p>
<ol class="simple">
<li><p>The mean of the sample means, <span class="math notranslate nohighlight">\(\mu_{\bar{x}}\)</span>, is equal to the mean of the population, <span class="math notranslate nohighlight">\(\mu\)</span>.</p></li>
<li><p>The standard deviation of the sample means, <span class="math notranslate nohighlight">\(\sigma_{\bar{x}}\)</span> is equal to <span class="math notranslate nohighlight">\(\frac{\sigma}{\sqrt{n}}\)</span>, assuming <span class="math notranslate nohighlight">\(\frac{n}{N} \leq 0.05\)</span>.</p></li>
<li><p>The shape of the sampling distribution of the sample means <span class="math notranslate nohighlight">\(\bar{x}\)</span> is normal, for whatever value of <span class="math notranslate nohighlight">\(n\)</span>.</p></li>
</ol>
<p>Let us consider a normally distributed population. For the sake of simplicity we use the standard normal distribution <span class="math notranslate nohighlight">\(N(\mu,\sigma)\)</span> with <span class="math notranslate nohighlight">\(\mu=0\)</span> and <span class="math notranslate nohighlight">\(\sigma=1\)</span>. Let us further calculate <span class="math notranslate nohighlight">\(\mu_{\bar{x}}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{\bar{x}}\)</span> for samples of sample sizes <span class="math notranslate nohighlight">\(n=5,15,30,50\)</span>.</p>
<p>Recall that for a large enough number of repeated sampling <span class="math notranslate nohighlight">\(\mu_{\bar{x}} \approx \mu\)</span>. Thus, <span class="math notranslate nohighlight">\(\mu_{\bar{x}}\)</span> of the different sampling distributions under consideration.</p>
<div class="math notranslate nohighlight">
\[\mu_{\bar x_{n=5}} = \mu_{\bar x_{n=15}} = \mu_{\bar x_{n=30}} = \mu_{\bar x_{n=50}} = \mu = 0\]</div>
<p>Recall the standard error of the sampling distribution <span class="math notranslate nohighlight">\(\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}} \)</span>. Thus, we can easily compute <span class="math notranslate nohighlight">\(\sigma_{\bar{x}}\)</span> for <span class="math notranslate nohighlight">\(n=5,15,30,50\)</span> elements. The different sampling distributions are visualized thereafter.</p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar x_{n=5}} = \frac{\sigma}{\sqrt{n}} =
\frac{1}{\sqrt{5}}\approx 0.447\]</div>
<div class="math notranslate nohighlight">
\[ \sigma_{\bar x_{n=15}} = \frac{\sigma}{\sqrt{n}} = \frac{1}{\sqrt{15}}\approx 0.258 \]</div>
<div class="math notranslate nohighlight">
\[ \sigma_{\bar x_{n=30}} = \frac{\sigma}{\sqrt{n}} = \frac{1}{\sqrt{30}}\approx 0.183 \]</div>
<div class="math notranslate nohighlight">
\[ \sigma_{\bar x_{n=50}} = \frac{\sigma}{\sqrt{n}} = \frac{1}{\sqrt{50}} \approx 0.141 \]</div>
<p><img alt="sampling_distribution_norm" src="_images/sampling_distribution_norm.png" /></p>
<p>There are two important observations regarding the sampling distribution of <span class="math notranslate nohighlight">\(\bar{x}\)</span></p>
<ol class="simple">
<li><p>The spread of the sampling distribution is smaller than the spread of the corresponding population distribution. In other words, <span class="math notranslate nohighlight">\(\sigma_{\bar{x}} &lt; \sigma\)</span>.</p></li>
<li><p>The standard deviation of the sampling distribution decreases as the sample size increases.</p></li>
</ol>
<p>In order to verify the 3rd claim from above, that the shape of the sampling distribution of <span class="math notranslate nohighlight">\(\bar{x}\)</span> is normal, whatever the value of <span class="math notranslate nohighlight">\(n\)</span>, we conduct a computational experiment. For a large enough number of times <mark> trials = 1000 </mark> we sample from the standard normal distribution <span class="math notranslate nohighlight">\(N(0,1)\)</span>, where each particular sample has a sample size of <span class="math notranslate nohighlight">\(n=5,15,30,50\)</span>. For each sample we calculate the sample mean <span class="math notranslate nohighlight">\(\bar{x}\)</span> and visualize the empirical probabilities. Afterwards we compare the empirical distribution of those probabilities with the sampling distributions calculated from the equations above.</p>
<p><img alt="sampling_diff_n" src="_images/sampling_diff_n.png" /></p>
<p>The figure verifies the 3rd claim above: The shape of the sampling distribution of <span class="math notranslate nohighlight">\(\bar{x}\)</span> is normal, for whatever value of <span class="math notranslate nohighlight">\(n\)</span>.</p>
<p>In addition, the figure shows that the distribution of the empirical probabilities (bars) fits well the sampling distribution (colored line), and that the standard deviation of the sampling distribution of <span class="math notranslate nohighlight">\(\bar{x}\)</span> decreases as the sample size increases. Recall, that the <span class="math notranslate nohighlight">\(y\)</span>-axis represents the <em>density</em>, which is the <strong>probability per unit value</strong> of the random variable. This is why the probability density can take a value greater than <span class="math notranslate nohighlight">\(1\)</span>, but only over a region with measure less than <span class="math notranslate nohighlight">\(1\)</span>.</p>
</div>
</div>
<div class="section" id="sampling-from-a-population-that-is-not-normally-distributed">
<h2>Sampling from a Population that is not Normally Distributed<a class="headerlink" href="#sampling-from-a-population-that-is-not-normally-distributed" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id2">
<h3>Shape of the Sampling Distribution<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>The shape of the sampling distribution relates to the following two cases.</p>
<ol class="simple">
<li><p>The population from which samples are drawn has a normal distribution.</p></li>
<li><p>The population from which samples are drawn does not have a normal distribution.</p></li>
</ol>
</div>
<div class="section" id="sampling-from-a-population-which-is-not-normally-distributed">
<h3>Sampling from a population which is not normally distributed<a class="headerlink" href="#sampling-from-a-population-which-is-not-normally-distributed" title="Permalink to this headline">¶</a></h3>
<p>In the previous section we discussed the shape of sample distributions if sampling from a normally distributed population. However, in real life applications we often do not know the actual shape of the population distribution.</p>
<p>In order to understand, how the shape of the distribution of the population of interest affects the shape of the sampling distribution we conduct an experiment. Let us consider three different continuous probability density functions: the <strong>uniform distribution</strong>, the <strong>beta distribution</strong>, and the <strong>gamma distribution</strong>. We do not go into details here, however the figure below shows, that these three PDFs are not normally distributed.</p>
<p><img alt="uniform_beta_gamma" src="_images/uniform_beta_gamma.png" /></p>
<p>Now we conduct the same experiment as in the previous section. For a large enough number of times <mark>trials = 1000 </mark> we sample from each particular distribution. However, this time each particular sample has a sample size <span class="math notranslate nohighlight">\(n=2,5,15,30\)</span>. For each sample we calculate the sample mean <span class="math notranslate nohighlight">\(\bar{x}\)</span> and visualize the empirical probabilities after <span class="math notranslate nohighlight">\(1000\)</span> trials.</p>
<p><img alt="sampling_beta_gamma_uniform" src="_images/sampling_beta_gamma_uniform.png" /></p>
<p>The figure shows that, in case of a population that is not normally distributed, the sampling distributions are not normal, when <span class="math notranslate nohighlight">\(n&lt;30\)</span>. However, the sampling distributions approximate a normal distribution, when <span class="math notranslate nohighlight">\(n&gt;30\)</span>. Also notice that the spread of the sampling distribution decreases as the sample size increases.</p>
<p>According to the <strong>central limit theorem</strong>, for a large sample size <span class="math notranslate nohighlight">\((n &gt; 30)\)</span>, the sampling distribution is approximately normal, irrespective of the shape of the population distribution.</p>
<p>The mean and standard deviation of the sampling distribution of <span class="math notranslate nohighlight">\(\bar{x}\)</span> are, respectively,</p>
<div class="math notranslate nohighlight">
\[\mu_{\bar{x}} = \mu \text{   and   } \sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}}\]</div>
<p>The sample size is usually considered to be large if <span class="math notranslate nohighlight">\(n \geq 30\)</span>.</p>
<p>Owing to the fact the sampling distribution approximates a normal distribution, the area under the curve of sampling distribution yields probabilistic information about the sample statistic.</p>
<p>Recall the <strong>Empirical Rule</strong>, also known as the <strong>68-95-99.7 rule</strong>. Consequently, applied to the sampling distribution the <span class="math notranslate nohighlight">\(68-95-99.7\)</span> rule implies that</p>
<ul class="simple">
<li><p>about <span class="math notranslate nohighlight">\(68.26\)</span>% of the sample means will be within one standard deviation of the population mean,</p></li>
<li><p><span class="math notranslate nohighlight">\(95.44\)</span>% of the sample means will be within two standard deviation of the population mean, and</p></li>
<li><p>about <span class="math notranslate nohighlight">\(99.74\)</span>% of the sample means will be within three standard deviations of the population mean.</p></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="getting_started.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Getting started</p>
        </div>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By ixians<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>